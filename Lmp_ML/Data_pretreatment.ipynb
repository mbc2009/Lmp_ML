{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mData_pretreatment.ipynb\u001b[m\u001b[m \u001b[31mModel_trainning.ipynb\u001b[m\u001b[m   \u001b[31mREADME.md\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# configuration\n",
    "class Conf:\n",
    "    '''\n",
    "    Pre-defined parameters for ML tranning\n",
    "    '''\n",
    "    # Paths\n",
    "    root                      = './'\n",
    "    path_to_Database          = os.path.join(root, 'DataBase')\n",
    "    path_to_inputs            = os.path.join(path_to_Database, 'LammpsDataFile')\n",
    "    path_to_temp_outputs      = os.path.join(path_to_Database, '3DGrid')\n",
    "    grid_DataBase_name        = '3D_Grids.h5'\n",
    "    path_to_grid_DataBase     = os.path.join(root, grid_DataBase_name)\n",
    "\n",
    "    # Supercelling: new boundary in X/Y/Z directions\n",
    "    GP_box_bounds_info_new = {'x': [600, 800],\n",
    "                              'y': [600, 800],\n",
    "                              'z': [600, 800]}\n",
    "\n",
    "    # 3D grid: number of grides in X/Y/Z directions\n",
    "    grid_size = [400, 400, 400]\n",
    "\n",
    "    # 3D grid: switch\n",
    "    grid_switch = True\n",
    "\n",
    "    # 指定温度区间\n",
    "    temp_list  = [373, 363, 353, 343]\n",
    "    sigma_list = range(8,19,1)\n",
    "    len_list   = range(2,21,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders for OUTPUT\n",
    "os.makedirs(Conf.path_to_inputs,  exist_ok=True)\n",
    "os.makedirs(Conf.path_to_temp_outputs, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic import\n",
    "import  os, math, psutil, h5py, shutil\n",
    "import  concurrent.futures\n",
    "from    concurrent.futures      import ProcessPoolExecutor\n",
    "from    tqdm                    import  tqdm\n",
    "from    pathlib                 import  Path  \n",
    "from    multiprocessing         import  Pool, Lock\n",
    "import  numpy                                       as np\n",
    "import  pandas                                      as pd\n",
    "import  torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 核心数:\t24\n",
      "CPU 线程数:\t24\n",
      "总内存:\t\t187.05 GB\n",
      "没有可用的 GPU\n"
     ]
    }
   ],
   "source": [
    "# check hardware\n",
    "print(f\"CPU 核心数:\\t{os.cpu_count()}\")\n",
    "print(f\"CPU 线程数:\\t{psutil.cpu_count(logical=True)}\")\n",
    "print(f\"总内存:\\t\\t{psutil.virtual_memory().total / (1024**3):.2f} GB\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"可用 GPU 数量:\\t{gpu_count}\")\n",
    "    for i in range(gpu_count):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i+1}:\\t\\t{gpu_name}\")\n",
    "else:\n",
    "    print(\"没有可用的 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Def Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取 lammps data file ##\n",
    "\n",
    "def fetch(len_i:int,\n",
    "          sigma_i:int,\n",
    "          temp_i:int,\n",
    "          item_i:str,\n",
    "          original_file_path:str\n",
    "          ):\n",
    "    '''\n",
    "    Fetch data from EXCEL\n",
    "    '''\n",
    "    # 加载Excel文件\n",
    "    df = pd.read_excel(original_file_path)\n",
    "    # 查找行号\n",
    "    row_number = df[\n",
    "        (df['len\\n(A)'] == len_i) &\n",
    "        (df['sigma\\n(A)'] == sigma_i) &\n",
    "        (df['temp\\n(k)'] == temp_i)\n",
    "    ].index\n",
    "    # 读取文件\n",
    "    return df.at[row_number[0], item_i]\n",
    "    \n",
    "class LmpGP_file_reader():\n",
    "    '''\n",
    "    read lammps data file\n",
    "    '''\n",
    "    def __init__(self, len: int, sigma: int, temp: int, path:int):\n",
    "        ## terminology of parameters\n",
    "        self.sigma          = sigma\n",
    "        self.len            = len\n",
    "        self.temp           = temp\n",
    "        ## working path\n",
    "        self.path           =  path\n",
    "        self.data_file      =  f\"data.3_len_{self.len}_sigma_{self.sigma}_pretreated\"\n",
    "        self.DataFile_path  =  os.path.join(self.path, self.data_file)\n",
    "        ## auto excecuting\n",
    "        self.read_GP_data_file()\n",
    "    def read_GP_data_file(self):\n",
    "        ### initialize\n",
    "        self.GP_atom_count, self.GP_box_bounds_info, self.GP_atom_data = None, {}, []\n",
    "        atom_section = False\n",
    "\n",
    "        ### extract info\n",
    "        with open(self.DataFile_path, 'r') as file:\n",
    "            for line in file:\n",
    "\n",
    "                ## Get the number of atoms\n",
    "                if line.strip().endswith(\"atoms\"):\n",
    "                    self.GP_atom_count = int(line.split()[0])\n",
    "\n",
    "                ## Get the box info\n",
    "                # boudnds\n",
    "                if 'xlo xhi' in line:\n",
    "                    self.GP_box_bounds_info['x'] = list(map(float, line.strip().split()[:2]))\n",
    "                if 'ylo yhi' in line:\n",
    "                    self.GP_box_bounds_info['y'] = list(map(float, line.strip().split()[:2]))\n",
    "                if 'zlo zhi' in line:\n",
    "                    self.GP_box_bounds_info['z'] = list(map(float, line.strip().split()[:2]))\n",
    "\n",
    "                ## Read atom data\n",
    "                # Check title\n",
    "                if 'Atoms' in line and '#' in line:\n",
    "                    atom_section = True\n",
    "                    continue\n",
    "                # read\n",
    "                if atom_section and line.strip():\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 6:  # valid line Ensured\n",
    "                        atom_id, atom_type, x, y, z = int(parts[0]), int(parts[1]), float(parts[4]), float(parts[5]), float(parts[6])\n",
    "                        self.GP_atom_data.append([atom_id, atom_type, x, y, z])\n",
    "\n",
    "            # calculate side length\n",
    "            x_length = float(self.GP_box_bounds_info['x'][1]) - float(self.GP_box_bounds_info['x'][0])\n",
    "            y_length = float(self.GP_box_bounds_info['y'][1]) - float(self.GP_box_bounds_info['y'][0])\n",
    "            z_length = float(self.GP_box_bounds_info['z'][1]) - float(self.GP_box_bounds_info['z'][0])\n",
    "            self.GP_box_lengths_info = np.array([x_length, y_length, z_length])\n",
    "\n",
    "        ### post-treatment\n",
    "        ## convert\n",
    "        self.GP_atom_data = np.array(self.GP_atom_data)\n",
    "        ## sorting\n",
    "        # 首先按照 type 排序，然后在 type 相同的情况下按 ID 排序\n",
    "        if hasattr(self, 'GP_atom_data') and self.GP_atom_data.size > 0:\n",
    "            # 获取排序后的索引\n",
    "            sorted_indices = np.lexsort((self.GP_atom_data[:, 0], self.GP_atom_data[:, 1]))  # 先按 ID，再按 type 排序\n",
    "            # 应用排序\n",
    "            self.GP_atom_data = self.GP_atom_data[sorted_indices]\n",
    "\n",
    "def extract_info(len_i:int,sigma_i:int,temp_i:int)->list:\n",
    "    '''\n",
    "    Extract info from lammps data file\n",
    "    '''\n",
    "    # 读取数据文件信息\n",
    "    GP                  = LmpGP_file_reader(len=len_i, sigma=sigma_i, temp=temp_i, path=Conf.path_to_inputs)\n",
    "    GP_atom_count       = GP.GP_atom_count\n",
    "    GP_box_bounds_info  = GP.GP_box_bounds_info\n",
    "\n",
    "    # 计算最大边界长度\n",
    "    x_length            = GP_box_bounds_info['x'][1] - GP_box_bounds_info['x'][0]\n",
    "    y_length            = GP_box_bounds_info['y'][1] - GP_box_bounds_info['y'][0]\n",
    "    z_length            = GP_box_bounds_info['z'][1] - GP_box_bounds_info['z'][0]\n",
    "    max_BoundLength_i   = np.amax([x_length, y_length, z_length])\n",
    "\n",
    "    # 计算最小边界长度\n",
    "    min_Bound_i  = np.amin([GP_box_bounds_info['x'][0],\n",
    "                            GP_box_bounds_info['x'][1],\n",
    "                            GP_box_bounds_info['y'][0],\n",
    "                            GP_box_bounds_info['y'][1],\n",
    "                            GP_box_bounds_info['z'][0],\n",
    "                            GP_box_bounds_info['z'][1]\n",
    "                            ])\n",
    "\n",
    "    # 存储信息\n",
    "    return [int(len_i),                   # 0\n",
    "            int(sigma_i),                 # 1\n",
    "            int(temp_i),                  # 2\n",
    "            GP_atom_count,                # 3\n",
    "            GP_box_bounds_info['x'][0],   # 4\n",
    "            GP_box_bounds_info['x'][1],   # 5\n",
    "            GP_box_bounds_info['y'][0],   # 6\n",
    "            GP_box_bounds_info['y'][1],   # 7\n",
    "            GP_box_bounds_info['z'][0],   # 8\n",
    "            GP_box_bounds_info['z'][1],   # 9\n",
    "            min_Bound_i,                  # 10\n",
    "            x_length,                     # 11\n",
    "            y_length,                     # 12\n",
    "            z_length,                     # 13\n",
    "            max_BoundLength_i]            # 14\n",
    "\n",
    "def find_info(mode: str, info_matrix:np.ndarray):\n",
    "    '''\n",
    "    找到拥有最大/最小 max_BoundLength_i 的那一行\n",
    "    '''\n",
    "    row             = []\n",
    "    bounds_info_i   = None\n",
    "    direction       = None\n",
    "\n",
    "    if mode == 'min':\n",
    "        row = info_matrix[np.argmin(info_matrix[:, 14])]\n",
    "    if mode == 'max':\n",
    "        row = info_matrix[np.argmax(info_matrix[:, 14])]\n",
    "    else:\n",
    "        print('select mode')\n",
    "\n",
    "    # 判断最{mode}的 'max_BoundLength_i' 所在方向\n",
    "    if row[14] == abs(row[5]-row[4]):\n",
    "        direction = 'x'\n",
    "        bounds_info_i = (row[4], row[5])\n",
    "    elif row[14] == abs(row[7]-row[6]):\n",
    "        direction = 'y'\n",
    "        bounds_info_i = (row[6], row[7])\n",
    "    elif row[14] == abs(row[9]-row[8]):\n",
    "        direction = 'z'\n",
    "        bounds_info_i = (row[8], row[9])\n",
    "\n",
    "    print(f\"拥有最{mode} 'x/y/z 最大边长' 的那一行是: {row}\")\n",
    "    print(f'起止坐标； {bounds_info_i}')\n",
    "    print(f\"最{mode}的方向是: {direction}，长度是: {row[14]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Supercelling 并存为 HDF5 文件 ##\n",
    "\n",
    "class DataFile_to_grid():\n",
    "    '''\n",
    "    1. Convert lammps data file to grids/ 3D numpy matrix\n",
    "    2. Supercelling to the desired size/ identical size\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 GP_data,\n",
    "                 grid_size: list,\n",
    "                 limits: dict,\n",
    "                 limits_new: dict,\n",
    "                 output_filename: str\n",
    "                 ):\n",
    "        '''\n",
    "        Input:\n",
    "        GP_data:          data file 原始数据\n",
    "        gride_size:       网格划分的尺寸\n",
    "        limits:           实际的 x/y/z 边界上下限\n",
    "        limits_new:       需要补全到的 x/y/z 边界上下限\n",
    "        output_filename:  输出文件名\n",
    "        '''\n",
    "        self.output_filename = output_filename\n",
    "        self.GP_data = GP_data\n",
    "        self.grid_size = grid_size\n",
    "        self.xmin, self.xmax = limits[\"x\"]\n",
    "        self.ymin, self.ymax = limits[\"y\"]\n",
    "        self.zmin, self.zmax = limits[\"z\"]\n",
    "        self.xmin_new, self.xmax_new = limits_new[\"x\"]\n",
    "        self.ymin_new, self.ymax_new = limits_new[\"y\"]\n",
    "        self.zmin_new, self.zmax_new = limits_new[\"z\"]\n",
    "\n",
    "        # 计算原始边界和新边界的长度\n",
    "        self.xlength = self.xmax - self.xmin\n",
    "        self.ylength = self.ymax - self.ymin\n",
    "        self.zlength = self.zmax - self.zmin\n",
    "        self.xlength_new = self.xmax_new - self.xmin_new\n",
    "        self.ylength_new = self.ymax_new - self.ymin_new\n",
    "        self.zlength_new = self.zmax_new - self.zmin_new\n",
    "\n",
    "        # 自动执行\n",
    "        self.GP_data_pretreat()\n",
    "        self.GP_data_analysis()\n",
    "        self.GP_data_aligning()\n",
    "        self.GP_data_to_grid()\n",
    "  \n",
    "    def GP_data_pretreat(self):\n",
    "        # 删除 atom type 列\n",
    "        self.GP_data = np.delete(self.GP_data, 1, axis=1)\n",
    "\n",
    "    def GP_data_analysis(self):\n",
    "        # 计算原子数\n",
    "        self.GP_atom_count = self.GP_data.shape[0]\n",
    "\n",
    "    def GP_data_aligning(self):\n",
    "        '''\n",
    "        对data file 进行补全（超胞 supercelling)\n",
    "        '''\n",
    "        # 计算需要复制的倍数，包括正方向和负方向\n",
    "        x_repeats_pos = int(np.ceil((self.xmax_new - self.xmax) / self.xlength))\n",
    "        x_repeats_neg = int(np.ceil((self.xmin - self.xmin_new) / self.xlength))\n",
    "        y_repeats_pos = int(np.ceil((self.ymax_new - self.ymax) / self.ylength))\n",
    "        y_repeats_neg = int(np.ceil((self.ymin - self.ymin_new) / self.ylength))\n",
    "        z_repeats_pos = int(np.ceil((self.zmax_new - self.zmax) / self.zlength))\n",
    "        z_repeats_neg = int(np.ceil((self.zmin - self.zmin_new) / self.zlength))\n",
    "\n",
    "        # 扩展原子坐标，包括正方向和负方向\n",
    "        extended_atoms  = []\n",
    "        new_atom_id     = 1\n",
    "        for i in range(-x_repeats_neg, x_repeats_pos + 1):\n",
    "            for j in range(-y_repeats_neg, y_repeats_pos + 1):\n",
    "                for k in range(-z_repeats_neg, z_repeats_pos + 1):\n",
    "                    for atom in self.GP_data:\n",
    "                        new_atom = atom.copy()\n",
    "                        new_atom[0] = new_atom_id  # 更新原子ID\n",
    "                        new_atom[1] = atom[1] + i * self.xlength\n",
    "                        new_atom[2] = atom[2] + j * self.ylength\n",
    "                        new_atom[3] = atom[3] + k * self.zlength\n",
    "                        extended_atoms.append(new_atom)\n",
    "                        new_atom_id += 1\n",
    "\n",
    "        # 转换为numpy数组\n",
    "        extended_atoms = np.array(extended_atoms)\n",
    "\n",
    "        # 过滤掉超出新边界的原子\n",
    "        extended_atoms = extended_atoms[\n",
    "            (extended_atoms[:, 1] >= self.xmin_new) & (extended_atoms[:, 1] < self.xmax_new) &\n",
    "            (extended_atoms[:, 2] >= self.ymin_new) & (extended_atoms[:, 2] < self.ymax_new) &\n",
    "            (extended_atoms[:, 3] >= self.zmin_new) & (extended_atoms[:, 3] < self.zmax_new)\n",
    "        ]\n",
    "\n",
    "        # 更新GP_data，并重新分配ID以确保连续\n",
    "        self.GP_data                = extended_atoms\n",
    "        self.GP_data[:, 0]          = np.arange(1, self.GP_data.shape[0] + 1)\n",
    "        self.GP_atom_count_extended = self.GP_data.shape[0]\n",
    "    \n",
    "    def GP_data_to_grid(self)-> np.ndarray:\n",
    "        '''\n",
    "        将原子数据转换为网格数据\n",
    "        '''\n",
    "        # N 格子, N+1 个点\n",
    "        x_bins = np.linspace(self.xmin_new, self.xmax_new, self.grid_size[0] + 1)\n",
    "        y_bins = np.linspace(self.ymin_new, self.ymax_new, self.grid_size[1] + 1)\n",
    "        z_bins = np.linspace(self.zmin_new, self.zmax_new, self.grid_size[2] + 1)\n",
    "\n",
    "        # 生成 X * Y * Z 形状的 3D 矩阵 (grid_size=(XY,Z))\n",
    "        grid_counts = np.zeros(self.grid_size)\n",
    "\n",
    "        for atom in self.GP_data:\n",
    "            x_idx = np.digitize(atom[1], x_bins) - 1    # digitize() 从1开始\n",
    "            y_idx = np.digitize(atom[2], y_bins) - 1\n",
    "            z_idx = np.digitize(atom[3], z_bins) - 1\n",
    "            if x_idx < self.grid_size[0] and y_idx < self.grid_size[1] and z_idx < self.grid_size[2]:\n",
    "                grid_counts[x_idx, y_idx, z_idx] += 1\n",
    "\n",
    "        self.grid_counts = grid_counts\n",
    "\n",
    "        # 打印结果以检查\n",
    "        #print(f\"Grid counts shape: {self.grid_counts.shape}\")\n",
    "        #print(self.grid_counts)\n",
    "\n",
    "        return grid_counts\n",
    "\n",
    "def process_single_DataFile_to_grid(len_i:int, sigma_i:int, temp_i:int)->np.ndarray:\n",
    "    \"\"\"\n",
    "    1. 处理单个 len_i sigma_i temp_i 写成 3D grid, 即 np.ndarray\n",
    "    2. 复制成4个温度\n",
    "    3. 返回 np.ndarray\n",
    "    \"\"\"\n",
    "    # 读取第一个温度的数据\n",
    "    GP                  = LmpGP_file_reader(len=len_i, sigma=sigma_i, temp=temp_i, path=Conf.path_to_inputs)\n",
    "    GP_atom_count       = GP.GP_atom_count\n",
    "    GP_box_bounds_info  = GP.GP_box_bounds_info\n",
    "    GP_atom_data        = GP.GP_atom_data\n",
    "\n",
    "    # Supercelling 处理\n",
    "    GP = DataFile_to_grid(GP_data           = GP_atom_data,                 # 原始的 data file info\n",
    "                          grid_size         = Conf.grid_size,               # 网格划分的尺寸\n",
    "                          limits            = GP_box_bounds_info,           # 实际的 x/y/z 边界上下限\n",
    "                          limits_new        = Conf.GP_box_bounds_info_new,  # 需要补全到的 x/y/z 边界上下限\n",
    "                          output_filename   = os.path.join(Conf.path_to_temp_outputs,f'CHECK_data_4_len_{len_i}_sigma_{sigma_i}_temp_i_{temp_i}.txt')\n",
    "                          )\n",
    "\n",
    "    # 提取 3D grid\n",
    "    GP_grid = GP.grid_counts\n",
    "    return GP_grid\n",
    "\n",
    "def process_AllSigma_DataFile_to_grid(len_i, sigma_i)->h5py:\n",
    "    '''\n",
    "    1. 处理 单个 len_i_Sigma_i 下 所有 temp_i 的 3D grid/ np.ndarray \n",
    "    2. 压缩保存为 h5py 文件\n",
    "    '''\n",
    "    # 指定 hdf5 文件位置\n",
    "    hdf5_file_path = os.path.join(Conf.path_to_temp_outputs, f\"len_{len_i}_sigma_{sigma_i}.h5\")\n",
    "    \n",
    "    # 读取标准的 grid file\n",
    "    grid_data_i   =  process_single_DataFile_to_grid(len_i,sigma_i,Conf.temp_list[0])\n",
    "\n",
    "    # 如果文件已经存在，跳过任务，避免并发冲突\n",
    "    if os.path.exists(hdf5_file_path):\n",
    "        print(f\"❌ Skipping {hdf5_file_path}, file already exists.\")\n",
    "        return \n",
    "    \n",
    "    ## 存储不同温度下的相同结构信息到 HDF5\n",
    "    # 打开 hdf5 file\n",
    "    with h5py.File(hdf5_file_path, 'w-') as hf:\n",
    "        for temp_i in Conf.temp_list:\n",
    "            # 定义名称\n",
    "            grid_name_i  =  f\"len_{len_i}_sigma_{sigma_i}_{temp_i}\"\n",
    "            # 存储\n",
    "            hf.create_dataset(grid_name_i, data=grid_data_i, compression=\"gzip\")  # 进行压缩，节省空间\n",
    "\n",
    "def process_parallel_DataFile_to_grid(len_i:int):\n",
    "    '''\n",
    "    1. 并行 处理 单 len_i 下 所有 Sigma_i 的 3D grid/ np.ndarray \n",
    "    2. 压缩保存为 h5py 文件\n",
    "    '''\n",
    "    # 获取 CPU 线程数\n",
    "    num_workers = min(psutil.cpu_count(logical=True),len(Conf.sigma_list))\n",
    "\n",
    "    # 进度条 + 多线程执行任务\n",
    "    with concurrent.futures.ThreadPoolExecutor(num_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_AllSigma_DataFile_to_grid, len_i, sigma_i): \n",
    "            (len_i, sigma_i)\n",
    "            for sigma_i in Conf.sigma_list\n",
    "        }\n",
    "\n",
    "        # 开始并行写入\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing DataFiles\"):\n",
    "            len_i, sigma_i = futures[future]  # 获取任务参数\n",
    "            try:\n",
    "                future.result()     # 确保任务成功完成\n",
    "            except Exception as e:\n",
    "                print(f\"❌ len_i={len_i}_sihma_{sigma_i}: {e}\")\n",
    "                \n",
    "        print(f\"✅ len_i={len_i}_sihma_{sigma_i}: HDF5 save completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 检查 hdf5 文件完整性 ##\n",
    "\n",
    "def check_hdf5_integrity(len_i,sigma_i):\n",
    "     '''\n",
    "     检查所有 hdf5 文件完整性\n",
    "     '''\n",
    "     file_name = f'len_{len_i}_sigma_{sigma_i}.h5'\n",
    "     file_path = os.path.join(Conf.path_to_temp_outputs,file_name)\n",
    "     try:\n",
    "          with h5py.File(file_path, \"r\") as h5f:\n",
    "               pass\n",
    "     except OSError as e:\n",
    "          print(f\"❌ {file_name} HDF5 文件可能损坏:\", e)\n",
    "\n",
    "def parallel_check_hdf5_integrity(len_i:int):\n",
    "    '''\n",
    "    并行检查完整性\n",
    "    '''\n",
    "    # 获取 CPU 线程数\n",
    "    num_workers = min(psutil.cpu_count(logical=True),len(Conf.sigma_list))\n",
    "\n",
    "    # 进度条 + 多线程执行任务\n",
    "    with concurrent.futures.ThreadPoolExecutor(num_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(check_hdf5_integrity, len_i, sigma_i): \n",
    "            (len_i, sigma_i)\n",
    "            for sigma_i in Conf.sigma_list\n",
    "        }\n",
    "\n",
    "        # 开始并行写入\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing DataFiles\"):\n",
    "            len_i, sigma_i = futures[future]  # 获取任务参数\n",
    "            try:\n",
    "                future.result()     # 确保任务成功完成\n",
    "            except Exception as e:\n",
    "                print(f\"❌ len_i_{len_i}_sigma_{sigma_i}: {e}\")\n",
    "                \n",
    "        print(f\"✅ len_i={len_i} HDF5 integrity check completed\")\n",
    "\n",
    "def check_hdf5_content(file_path=Conf.path_to_grid_DataBase):\n",
    "     \n",
    "     # 初始化数据集计数器\n",
    "     dataset_count = 0  \n",
    "\n",
    "     # 定义一个内部函数用于遍历 HDF5 文件\n",
    "     def count_datasets(name, obj):\n",
    "          nonlocal dataset_count\n",
    "          if isinstance(obj, h5py.Dataset):  # 判断是否为数据集\n",
    "               dataset_count += 1\n",
    "          elif isinstance(obj, h5py.Group):  # 判断是否为组\n",
    "               pass  # 如果是组，不计数\n",
    "\n",
    "     with h5py.File(file_path, \"r\") as h5f:\n",
    "          # 打印\n",
    "          print(f\"文件结构:\")\n",
    "          # 遍历文件内容以计数\n",
    "          h5f.visititems(count_datasets)\n",
    "          # 打印所有内变量名字\n",
    "          h5f.visit(print) \n",
    "\n",
    "     print(f'文件数: {dataset_count}')\n",
    "\n",
    "     return dataset_count # 文件数\n",
    "\n",
    "\n",
    "\n",
    "## 汇总所有 hdf5 文件 ##\n",
    "\n",
    "def extract_single_hdf5_file(file_name:str)-> dict:\n",
    "     '''\n",
    "     读取单个 HDF5 文件中的所有数据集\n",
    "     :param len_i: len_i 参数\n",
    "     :param sigma_i: sigma_i 参数\n",
    "     :return: 字典，键为数据集名称，值为数据集数据\n",
    "     '''\n",
    "     file_path   = os.path.join(Conf.path_to_temp_outputs, f'{file_name}.h5')\n",
    "     datasets_i  = {}\n",
    "          \n",
    "     with h5py.File(file_path, \"r\") as h5f:\n",
    "          # 遍历文件中的所有数据集\n",
    "          def collect_datasets(name, obj):\n",
    "               if isinstance(obj, h5py.Dataset):\n",
    "                    # 将数据集数据存储到字典中\n",
    "                    datasets_i[name] = obj[()] \n",
    "\n",
    "          h5f.visititems(collect_datasets)\n",
    "\n",
    "     return datasets_i\n",
    "\n",
    "\n",
    "\n",
    "def merge_hdf5_files(output_file=Conf.path_to_grid_DataBase):\n",
    "    \"\"\"\n",
    "    并行读取所有 HDF5 文件并将提取出的矩阵添加到目标 HDF5 文件中。\n",
    "    每个矩阵的变量名等于字典中的键值。\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建或更新 HDF5 文件\n",
    "    with h5py.File(output_file, 'a') as hf:  # 'a' 模式：追加数据\n",
    "          for len_i in Conf.len_list:\n",
    "               for sigma_i in tqdm(Conf.sigma_list, total=len(Conf.sigma_list), desc=f\"len_{len_i}\\t\"):\n",
    "                    # 提取单个 HDF5 文件中的数据\n",
    "                    datasets_i = extract_single_hdf5_file(f'len_{len_i}_sigma_{sigma_i}')                   \n",
    "                    try: \n",
    "                         # 遍历提取出的数据字典并存入 HDF5 文件\n",
    "                         for dataset_name, dataset_data in datasets_i.items():\n",
    "                              # 若已存在相同名称的数据集，删除后重新写入\n",
    "                              if dataset_name in hf:\n",
    "                                   del hf[dataset_name]  \n",
    "\n",
    "                              hf.create_dataset(dataset_name, data=dataset_data, compression=\"gzip\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                         print(f\"❌ len_i_{len_i}_sigma_{sigma_i}: {e}\")\n",
    "          \n",
    "    print(f\"✅ All extracted matrices have been merged into {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CHECK\n",
    "找到合适的supercelling 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 836/836 [01:47<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info list shape:\t(836, 15)\n",
      "reference length:\t836,15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Collect data files info ##\n",
    "\n",
    "# 初始化一个主列表用于存储所有信息\n",
    "info_mtx = np.empty((0, 15))\n",
    "\n",
    "# 创建一个线程池\n",
    "with concurrent.futures.ThreadPoolExecutor(psutil.cpu_count(logical=True)) as executor:\n",
    "    # 生成所有任务\n",
    "    futures = {executor.submit(extract_info, len_i, sigma_i, temp_i):\n",
    "                        (len_i, sigma_i, temp_i)\n",
    "                        for len_i in range(2, 21, 1)\n",
    "                        for sigma_i in range(8, 19, 1)\n",
    "                        for temp_i in range(373, 333, -10)}\n",
    "\n",
    "    # 收集所有返回的数据\n",
    "    results = [future.result() for future in tqdm(concurrent.futures.as_completed(futures),total=len(futures),desc=\"Processing DataFiles\")]\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "info_mtx = np.array(results)\n",
    "\n",
    "# 打印结果以检查\n",
    "print(f'info list shape:\\t{info_mtx.shape}')\n",
    "print(f'reference length:\\t{len(Conf.len_list)*len(Conf.sigma_list)*len(Conf.temp_list)},{15}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select mode\n",
      "拥有最min 'x/y/z 最大边长' 的那一行是: [3.00000000e+00 8.00000000e+00 3.63000000e+02 3.83600000e+03\n",
      " 6.51675695e+02 7.08250305e+02 6.52167825e+02 7.08467175e+02\n",
      " 6.51941735e+02 7.08693265e+02 6.51675695e+02 5.65746094e+01\n",
      " 5.62993504e+01 5.67515307e+01 5.67515307e+01]\n",
      "起止坐标； (np.float64(651.9417346706942), np.float64(708.6932653293076))\n",
      "最min的方向是: z，长度是: 56.75153065861332\n",
      "\n",
      "\n",
      "拥有最max 'x/y/z 最大边长' 的那一行是: [4.00000000e+00 1.80000000e+01 3.43000000e+02 4.27600000e+03\n",
      " 6.00449820e+02 7.59476180e+02 6.00133917e+02 7.60501083e+02\n",
      " 6.00572822e+02 7.60062178e+02 6.00133917e+02 1.59026359e+02\n",
      " 1.60367165e+02 1.59489356e+02 1.60367165e+02]\n",
      "起止坐标； (np.float64(600.1339173401502), np.float64(760.5010826598495))\n",
      "最max的方向是: y，长度是: 160.36716531969932\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 寻找最大和最短的 box 长度 ##\n",
    "find_info('min', info_mtx) # 最小\n",
    "find_info('max', info_mtx) # 最小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.EXE\n",
    "并行执行 lammps data file -> supercelling -> HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [02:50<00:00, 15.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=2_sihma_10: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 2817.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=2 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 2\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [02:46<00:00, 15.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=3_sihma_8: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 2170.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=3 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 3\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [02:45<00:00, 15.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=4_sihma_8: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 1516.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=4 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 4\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [02:53<00:00, 15.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=5_sihma_9: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 3892.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=5 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 5\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [02:57<00:00, 16.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=6_sihma_12: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 1723.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=6 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 6\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:05<00:00, 16.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=7_sihma_11: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 3960.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=7 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 7\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:07<00:00, 17.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=8_sihma_15: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 2516.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=8 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 8\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:16<00:00, 17.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=9_sihma_15: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 3012.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=9 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 9\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:20<00:00, 18.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=10_sihma_13: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 4193.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=10 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 10\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:24<00:00, 18.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=11_sihma_12: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 2980.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=11 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 11\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:29<00:00, 19.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=12_sihma_8: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 4242.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=12 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 12\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:35<00:00, 19.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=13_sihma_13: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 2169.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=13 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 13\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:41<00:00, 20.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=14_sihma_14: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 1573.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=14 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 14\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:48<00:00, 20.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=15_sihma_12: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 3089.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=15 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 15\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:51<00:00, 21.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=16_sihma_10: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 4127.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=16 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 16\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [03:59<00:00, 21.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=17_sihma_14: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 3067.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=17 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 17\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [04:06<00:00, 22.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=18_sihma_11: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 2022.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=18 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 18\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [04:14<00:00, 23.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=19_sihma_9: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 3678.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=19 HDF5 integrity check completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_i = 19\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [04:21<00:00, 23.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=20_sihma_8: HDF5 save completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFiles: 100%|██████████| 11/11 [00:00<00:00, 3225.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ len_i=20 HDF5 integrity check completed\n"
     ]
    }
   ],
   "source": [
    "len_i = 20\n",
    "process_parallel_DataFile_to_grid(len_i)\n",
    "parallel_check_hdf5_integrity(len_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 合并\n",
    "合并所有HDF5文件为一个整体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "len_2\t: 100%|██████████| 11/11 [03:33<00:00, 19.38s/it]\n",
      "len_3\t: 100%|██████████| 11/11 [03:25<00:00, 18.69s/it]\n",
      "len_4\t: 100%|██████████| 11/11 [03:23<00:00, 18.49s/it]\n",
      "len_5\t: 100%|██████████| 11/11 [03:22<00:00, 18.43s/it]\n",
      "len_6\t: 100%|██████████| 11/11 [03:23<00:00, 18.49s/it]\n",
      "len_7\t: 100%|██████████| 11/11 [03:23<00:00, 18.49s/it]\n",
      "len_8\t: 100%|██████████| 11/11 [03:23<00:00, 18.50s/it]\n",
      "len_9\t: 100%|██████████| 11/11 [03:24<00:00, 18.55s/it]\n",
      "len_10\t: 100%|██████████| 11/11 [03:23<00:00, 18.50s/it]\n",
      "len_11\t: 100%|██████████| 11/11 [03:24<00:00, 18.62s/it]\n",
      "len_12\t: 100%|██████████| 11/11 [03:24<00:00, 18.55s/it]\n",
      "len_13\t: 100%|██████████| 11/11 [03:28<00:00, 18.95s/it]\n",
      "len_14\t: 100%|██████████| 11/11 [03:25<00:00, 18.72s/it]\n",
      "len_15\t: 100%|██████████| 11/11 [03:22<00:00, 18.40s/it]\n",
      "len_16\t: 100%|██████████| 11/11 [03:22<00:00, 18.37s/it]\n",
      "len_17\t: 100%|██████████| 11/11 [03:22<00:00, 18.45s/it]\n",
      "len_18\t: 100%|██████████| 11/11 [03:22<00:00, 18.43s/it]\n",
      "len_19\t: 100%|██████████| 11/11 [03:23<00:00, 18.54s/it]\n",
      "len_20\t: 100%|██████████| 11/11 [03:24<00:00, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All extracted matrices have been merged into 3D_Grids.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "merge_hdf5_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 后处理\n",
    "检查完整性并删除临时文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据库存在 ✅\n",
      "文件结构:\n",
      "len_10_sigma_10_343\n",
      "len_10_sigma_10_353\n",
      "len_10_sigma_10_363\n",
      "len_10_sigma_10_373\n",
      "len_10_sigma_11_343\n",
      "len_10_sigma_11_353\n",
      "len_10_sigma_11_363\n",
      "len_10_sigma_11_373\n",
      "len_10_sigma_12_343\n",
      "len_10_sigma_12_353\n",
      "len_10_sigma_12_363\n",
      "len_10_sigma_12_373\n",
      "len_10_sigma_13_343\n",
      "len_10_sigma_13_353\n",
      "len_10_sigma_13_363\n",
      "len_10_sigma_13_373\n",
      "len_10_sigma_14_343\n",
      "len_10_sigma_14_353\n",
      "len_10_sigma_14_363\n",
      "len_10_sigma_14_373\n",
      "len_10_sigma_15_343\n",
      "len_10_sigma_15_353\n",
      "len_10_sigma_15_363\n",
      "len_10_sigma_15_373\n",
      "len_10_sigma_16_343\n",
      "len_10_sigma_16_353\n",
      "len_10_sigma_16_363\n",
      "len_10_sigma_16_373\n",
      "len_10_sigma_17_343\n",
      "len_10_sigma_17_353\n",
      "len_10_sigma_17_363\n",
      "len_10_sigma_17_373\n",
      "len_10_sigma_18_343\n",
      "len_10_sigma_18_353\n",
      "len_10_sigma_18_363\n",
      "len_10_sigma_18_373\n",
      "len_10_sigma_8_343\n",
      "len_10_sigma_8_353\n",
      "len_10_sigma_8_363\n",
      "len_10_sigma_8_373\n",
      "len_10_sigma_9_343\n",
      "len_10_sigma_9_353\n",
      "len_10_sigma_9_363\n",
      "len_10_sigma_9_373\n",
      "len_11_sigma_10_343\n",
      "len_11_sigma_10_353\n",
      "len_11_sigma_10_363\n",
      "len_11_sigma_10_373\n",
      "len_11_sigma_11_343\n",
      "len_11_sigma_11_353\n",
      "len_11_sigma_11_363\n",
      "len_11_sigma_11_373\n",
      "len_11_sigma_12_343\n",
      "len_11_sigma_12_353\n",
      "len_11_sigma_12_363\n",
      "len_11_sigma_12_373\n",
      "len_11_sigma_13_343\n",
      "len_11_sigma_13_353\n",
      "len_11_sigma_13_363\n",
      "len_11_sigma_13_373\n",
      "len_11_sigma_14_343\n",
      "len_11_sigma_14_353\n",
      "len_11_sigma_14_363\n",
      "len_11_sigma_14_373\n",
      "len_11_sigma_15_343\n",
      "len_11_sigma_15_353\n",
      "len_11_sigma_15_363\n",
      "len_11_sigma_15_373\n",
      "len_11_sigma_16_343\n",
      "len_11_sigma_16_353\n",
      "len_11_sigma_16_363\n",
      "len_11_sigma_16_373\n",
      "len_11_sigma_17_343\n",
      "len_11_sigma_17_353\n",
      "len_11_sigma_17_363\n",
      "len_11_sigma_17_373\n",
      "len_11_sigma_18_343\n",
      "len_11_sigma_18_353\n",
      "len_11_sigma_18_363\n",
      "len_11_sigma_18_373\n",
      "len_11_sigma_8_343\n",
      "len_11_sigma_8_353\n",
      "len_11_sigma_8_363\n",
      "len_11_sigma_8_373\n",
      "len_11_sigma_9_343\n",
      "len_11_sigma_9_353\n",
      "len_11_sigma_9_363\n",
      "len_11_sigma_9_373\n",
      "len_12_sigma_10_343\n",
      "len_12_sigma_10_353\n",
      "len_12_sigma_10_363\n",
      "len_12_sigma_10_373\n",
      "len_12_sigma_11_343\n",
      "len_12_sigma_11_353\n",
      "len_12_sigma_11_363\n",
      "len_12_sigma_11_373\n",
      "len_12_sigma_12_343\n",
      "len_12_sigma_12_353\n",
      "len_12_sigma_12_363\n",
      "len_12_sigma_12_373\n",
      "len_12_sigma_13_343\n",
      "len_12_sigma_13_353\n",
      "len_12_sigma_13_363\n",
      "len_12_sigma_13_373\n",
      "len_12_sigma_14_343\n",
      "len_12_sigma_14_353\n",
      "len_12_sigma_14_363\n",
      "len_12_sigma_14_373\n",
      "len_12_sigma_15_343\n",
      "len_12_sigma_15_353\n",
      "len_12_sigma_15_363\n",
      "len_12_sigma_15_373\n",
      "len_12_sigma_16_343\n",
      "len_12_sigma_16_353\n",
      "len_12_sigma_16_363\n",
      "len_12_sigma_16_373\n",
      "len_12_sigma_17_343\n",
      "len_12_sigma_17_353\n",
      "len_12_sigma_17_363\n",
      "len_12_sigma_17_373\n",
      "len_12_sigma_18_343\n",
      "len_12_sigma_18_353\n",
      "len_12_sigma_18_363\n",
      "len_12_sigma_18_373\n",
      "len_12_sigma_8_343\n",
      "len_12_sigma_8_353\n",
      "len_12_sigma_8_363\n",
      "len_12_sigma_8_373\n",
      "len_12_sigma_9_343\n",
      "len_12_sigma_9_353\n",
      "len_12_sigma_9_363\n",
      "len_12_sigma_9_373\n",
      "len_13_sigma_10_343\n",
      "len_13_sigma_10_353\n",
      "len_13_sigma_10_363\n",
      "len_13_sigma_10_373\n",
      "len_13_sigma_11_343\n",
      "len_13_sigma_11_353\n",
      "len_13_sigma_11_363\n",
      "len_13_sigma_11_373\n",
      "len_13_sigma_12_343\n",
      "len_13_sigma_12_353\n",
      "len_13_sigma_12_363\n",
      "len_13_sigma_12_373\n",
      "len_13_sigma_13_343\n",
      "len_13_sigma_13_353\n",
      "len_13_sigma_13_363\n",
      "len_13_sigma_13_373\n",
      "len_13_sigma_14_343\n",
      "len_13_sigma_14_353\n",
      "len_13_sigma_14_363\n",
      "len_13_sigma_14_373\n",
      "len_13_sigma_15_343\n",
      "len_13_sigma_15_353\n",
      "len_13_sigma_15_363\n",
      "len_13_sigma_15_373\n",
      "len_13_sigma_16_343\n",
      "len_13_sigma_16_353\n",
      "len_13_sigma_16_363\n",
      "len_13_sigma_16_373\n",
      "len_13_sigma_17_343\n",
      "len_13_sigma_17_353\n",
      "len_13_sigma_17_363\n",
      "len_13_sigma_17_373\n",
      "len_13_sigma_18_343\n",
      "len_13_sigma_18_353\n",
      "len_13_sigma_18_363\n",
      "len_13_sigma_18_373\n",
      "len_13_sigma_8_343\n",
      "len_13_sigma_8_353\n",
      "len_13_sigma_8_363\n",
      "len_13_sigma_8_373\n",
      "len_13_sigma_9_343\n",
      "len_13_sigma_9_353\n",
      "len_13_sigma_9_363\n",
      "len_13_sigma_9_373\n",
      "len_14_sigma_10_343\n",
      "len_14_sigma_10_353\n",
      "len_14_sigma_10_363\n",
      "len_14_sigma_10_373\n",
      "len_14_sigma_11_343\n",
      "len_14_sigma_11_353\n",
      "len_14_sigma_11_363\n",
      "len_14_sigma_11_373\n",
      "len_14_sigma_12_343\n",
      "len_14_sigma_12_353\n",
      "len_14_sigma_12_363\n",
      "len_14_sigma_12_373\n",
      "len_14_sigma_13_343\n",
      "len_14_sigma_13_353\n",
      "len_14_sigma_13_363\n",
      "len_14_sigma_13_373\n",
      "len_14_sigma_14_343\n",
      "len_14_sigma_14_353\n",
      "len_14_sigma_14_363\n",
      "len_14_sigma_14_373\n",
      "len_14_sigma_15_343\n",
      "len_14_sigma_15_353\n",
      "len_14_sigma_15_363\n",
      "len_14_sigma_15_373\n",
      "len_14_sigma_16_343\n",
      "len_14_sigma_16_353\n",
      "len_14_sigma_16_363\n",
      "len_14_sigma_16_373\n",
      "len_14_sigma_17_343\n",
      "len_14_sigma_17_353\n",
      "len_14_sigma_17_363\n",
      "len_14_sigma_17_373\n",
      "len_14_sigma_18_343\n",
      "len_14_sigma_18_353\n",
      "len_14_sigma_18_363\n",
      "len_14_sigma_18_373\n",
      "len_14_sigma_8_343\n",
      "len_14_sigma_8_353\n",
      "len_14_sigma_8_363\n",
      "len_14_sigma_8_373\n",
      "len_14_sigma_9_343\n",
      "len_14_sigma_9_353\n",
      "len_14_sigma_9_363\n",
      "len_14_sigma_9_373\n",
      "len_15_sigma_10_343\n",
      "len_15_sigma_10_353\n",
      "len_15_sigma_10_363\n",
      "len_15_sigma_10_373\n",
      "len_15_sigma_11_343\n",
      "len_15_sigma_11_353\n",
      "len_15_sigma_11_363\n",
      "len_15_sigma_11_373\n",
      "len_15_sigma_12_343\n",
      "len_15_sigma_12_353\n",
      "len_15_sigma_12_363\n",
      "len_15_sigma_12_373\n",
      "len_15_sigma_13_343\n",
      "len_15_sigma_13_353\n",
      "len_15_sigma_13_363\n",
      "len_15_sigma_13_373\n",
      "len_15_sigma_14_343\n",
      "len_15_sigma_14_353\n",
      "len_15_sigma_14_363\n",
      "len_15_sigma_14_373\n",
      "len_15_sigma_15_343\n",
      "len_15_sigma_15_353\n",
      "len_15_sigma_15_363\n",
      "len_15_sigma_15_373\n",
      "len_15_sigma_16_343\n",
      "len_15_sigma_16_353\n",
      "len_15_sigma_16_363\n",
      "len_15_sigma_16_373\n",
      "len_15_sigma_17_343\n",
      "len_15_sigma_17_353\n",
      "len_15_sigma_17_363\n",
      "len_15_sigma_17_373\n",
      "len_15_sigma_18_343\n",
      "len_15_sigma_18_353\n",
      "len_15_sigma_18_363\n",
      "len_15_sigma_18_373\n",
      "len_15_sigma_8_343\n",
      "len_15_sigma_8_353\n",
      "len_15_sigma_8_363\n",
      "len_15_sigma_8_373\n",
      "len_15_sigma_9_343\n",
      "len_15_sigma_9_353\n",
      "len_15_sigma_9_363\n",
      "len_15_sigma_9_373\n",
      "len_16_sigma_10_343\n",
      "len_16_sigma_10_353\n",
      "len_16_sigma_10_363\n",
      "len_16_sigma_10_373\n",
      "len_16_sigma_11_343\n",
      "len_16_sigma_11_353\n",
      "len_16_sigma_11_363\n",
      "len_16_sigma_11_373\n",
      "len_16_sigma_12_343\n",
      "len_16_sigma_12_353\n",
      "len_16_sigma_12_363\n",
      "len_16_sigma_12_373\n",
      "len_16_sigma_13_343\n",
      "len_16_sigma_13_353\n",
      "len_16_sigma_13_363\n",
      "len_16_sigma_13_373\n",
      "len_16_sigma_14_343\n",
      "len_16_sigma_14_353\n",
      "len_16_sigma_14_363\n",
      "len_16_sigma_14_373\n",
      "len_16_sigma_15_343\n",
      "len_16_sigma_15_353\n",
      "len_16_sigma_15_363\n",
      "len_16_sigma_15_373\n",
      "len_16_sigma_16_343\n",
      "len_16_sigma_16_353\n",
      "len_16_sigma_16_363\n",
      "len_16_sigma_16_373\n",
      "len_16_sigma_17_343\n",
      "len_16_sigma_17_353\n",
      "len_16_sigma_17_363\n",
      "len_16_sigma_17_373\n",
      "len_16_sigma_18_343\n",
      "len_16_sigma_18_353\n",
      "len_16_sigma_18_363\n",
      "len_16_sigma_18_373\n",
      "len_16_sigma_8_343\n",
      "len_16_sigma_8_353\n",
      "len_16_sigma_8_363\n",
      "len_16_sigma_8_373\n",
      "len_16_sigma_9_343\n",
      "len_16_sigma_9_353\n",
      "len_16_sigma_9_363\n",
      "len_16_sigma_9_373\n",
      "len_17_sigma_10_343\n",
      "len_17_sigma_10_353\n",
      "len_17_sigma_10_363\n",
      "len_17_sigma_10_373\n",
      "len_17_sigma_11_343\n",
      "len_17_sigma_11_353\n",
      "len_17_sigma_11_363\n",
      "len_17_sigma_11_373\n",
      "len_17_sigma_12_343\n",
      "len_17_sigma_12_353\n",
      "len_17_sigma_12_363\n",
      "len_17_sigma_12_373\n",
      "len_17_sigma_13_343\n",
      "len_17_sigma_13_353\n",
      "len_17_sigma_13_363\n",
      "len_17_sigma_13_373\n",
      "len_17_sigma_14_343\n",
      "len_17_sigma_14_353\n",
      "len_17_sigma_14_363\n",
      "len_17_sigma_14_373\n",
      "len_17_sigma_15_343\n",
      "len_17_sigma_15_353\n",
      "len_17_sigma_15_363\n",
      "len_17_sigma_15_373\n",
      "len_17_sigma_16_343\n",
      "len_17_sigma_16_353\n",
      "len_17_sigma_16_363\n",
      "len_17_sigma_16_373\n",
      "len_17_sigma_17_343\n",
      "len_17_sigma_17_353\n",
      "len_17_sigma_17_363\n",
      "len_17_sigma_17_373\n",
      "len_17_sigma_18_343\n",
      "len_17_sigma_18_353\n",
      "len_17_sigma_18_363\n",
      "len_17_sigma_18_373\n",
      "len_17_sigma_8_343\n",
      "len_17_sigma_8_353\n",
      "len_17_sigma_8_363\n",
      "len_17_sigma_8_373\n",
      "len_17_sigma_9_343\n",
      "len_17_sigma_9_353\n",
      "len_17_sigma_9_363\n",
      "len_17_sigma_9_373\n",
      "len_18_sigma_10_343\n",
      "len_18_sigma_10_353\n",
      "len_18_sigma_10_363\n",
      "len_18_sigma_10_373\n",
      "len_18_sigma_11_343\n",
      "len_18_sigma_11_353\n",
      "len_18_sigma_11_363\n",
      "len_18_sigma_11_373\n",
      "len_18_sigma_12_343\n",
      "len_18_sigma_12_353\n",
      "len_18_sigma_12_363\n",
      "len_18_sigma_12_373\n",
      "len_18_sigma_13_343\n",
      "len_18_sigma_13_353\n",
      "len_18_sigma_13_363\n",
      "len_18_sigma_13_373\n",
      "len_18_sigma_14_343\n",
      "len_18_sigma_14_353\n",
      "len_18_sigma_14_363\n",
      "len_18_sigma_14_373\n",
      "len_18_sigma_15_343\n",
      "len_18_sigma_15_353\n",
      "len_18_sigma_15_363\n",
      "len_18_sigma_15_373\n",
      "len_18_sigma_16_343\n",
      "len_18_sigma_16_353\n",
      "len_18_sigma_16_363\n",
      "len_18_sigma_16_373\n",
      "len_18_sigma_17_343\n",
      "len_18_sigma_17_353\n",
      "len_18_sigma_17_363\n",
      "len_18_sigma_17_373\n",
      "len_18_sigma_18_343\n",
      "len_18_sigma_18_353\n",
      "len_18_sigma_18_363\n",
      "len_18_sigma_18_373\n",
      "len_18_sigma_8_343\n",
      "len_18_sigma_8_353\n",
      "len_18_sigma_8_363\n",
      "len_18_sigma_8_373\n",
      "len_18_sigma_9_343\n",
      "len_18_sigma_9_353\n",
      "len_18_sigma_9_363\n",
      "len_18_sigma_9_373\n",
      "len_19_sigma_10_343\n",
      "len_19_sigma_10_353\n",
      "len_19_sigma_10_363\n",
      "len_19_sigma_10_373\n",
      "len_19_sigma_11_343\n",
      "len_19_sigma_11_353\n",
      "len_19_sigma_11_363\n",
      "len_19_sigma_11_373\n",
      "len_19_sigma_12_343\n",
      "len_19_sigma_12_353\n",
      "len_19_sigma_12_363\n",
      "len_19_sigma_12_373\n",
      "len_19_sigma_13_343\n",
      "len_19_sigma_13_353\n",
      "len_19_sigma_13_363\n",
      "len_19_sigma_13_373\n",
      "len_19_sigma_14_343\n",
      "len_19_sigma_14_353\n",
      "len_19_sigma_14_363\n",
      "len_19_sigma_14_373\n",
      "len_19_sigma_15_343\n",
      "len_19_sigma_15_353\n",
      "len_19_sigma_15_363\n",
      "len_19_sigma_15_373\n",
      "len_19_sigma_16_343\n",
      "len_19_sigma_16_353\n",
      "len_19_sigma_16_363\n",
      "len_19_sigma_16_373\n",
      "len_19_sigma_17_343\n",
      "len_19_sigma_17_353\n",
      "len_19_sigma_17_363\n",
      "len_19_sigma_17_373\n",
      "len_19_sigma_18_343\n",
      "len_19_sigma_18_353\n",
      "len_19_sigma_18_363\n",
      "len_19_sigma_18_373\n",
      "len_19_sigma_8_343\n",
      "len_19_sigma_8_353\n",
      "len_19_sigma_8_363\n",
      "len_19_sigma_8_373\n",
      "len_19_sigma_9_343\n",
      "len_19_sigma_9_353\n",
      "len_19_sigma_9_363\n",
      "len_19_sigma_9_373\n",
      "len_20_sigma_10_343\n",
      "len_20_sigma_10_353\n",
      "len_20_sigma_10_363\n",
      "len_20_sigma_10_373\n",
      "len_20_sigma_11_343\n",
      "len_20_sigma_11_353\n",
      "len_20_sigma_11_363\n",
      "len_20_sigma_11_373\n",
      "len_20_sigma_12_343\n",
      "len_20_sigma_12_353\n",
      "len_20_sigma_12_363\n",
      "len_20_sigma_12_373\n",
      "len_20_sigma_13_343\n",
      "len_20_sigma_13_353\n",
      "len_20_sigma_13_363\n",
      "len_20_sigma_13_373\n",
      "len_20_sigma_14_343\n",
      "len_20_sigma_14_353\n",
      "len_20_sigma_14_363\n",
      "len_20_sigma_14_373\n",
      "len_20_sigma_15_343\n",
      "len_20_sigma_15_353\n",
      "len_20_sigma_15_363\n",
      "len_20_sigma_15_373\n",
      "len_20_sigma_16_343\n",
      "len_20_sigma_16_353\n",
      "len_20_sigma_16_363\n",
      "len_20_sigma_16_373\n",
      "len_20_sigma_17_343\n",
      "len_20_sigma_17_353\n",
      "len_20_sigma_17_363\n",
      "len_20_sigma_17_373\n",
      "len_20_sigma_18_343\n",
      "len_20_sigma_18_353\n",
      "len_20_sigma_18_363\n",
      "len_20_sigma_18_373\n",
      "len_20_sigma_8_343\n",
      "len_20_sigma_8_353\n",
      "len_20_sigma_8_363\n",
      "len_20_sigma_8_373\n",
      "len_20_sigma_9_343\n",
      "len_20_sigma_9_353\n",
      "len_20_sigma_9_363\n",
      "len_20_sigma_9_373\n",
      "len_2_sigma_10_343\n",
      "len_2_sigma_10_353\n",
      "len_2_sigma_10_363\n",
      "len_2_sigma_10_373\n",
      "len_2_sigma_11_343\n",
      "len_2_sigma_11_353\n",
      "len_2_sigma_11_363\n",
      "len_2_sigma_11_373\n",
      "len_2_sigma_12_343\n",
      "len_2_sigma_12_353\n",
      "len_2_sigma_12_363\n",
      "len_2_sigma_12_373\n",
      "len_2_sigma_13_343\n",
      "len_2_sigma_13_353\n",
      "len_2_sigma_13_363\n",
      "len_2_sigma_13_373\n",
      "len_2_sigma_14_343\n",
      "len_2_sigma_14_353\n",
      "len_2_sigma_14_363\n",
      "len_2_sigma_14_373\n",
      "len_2_sigma_15_343\n",
      "len_2_sigma_15_353\n",
      "len_2_sigma_15_363\n",
      "len_2_sigma_15_373\n",
      "len_2_sigma_16_343\n",
      "len_2_sigma_16_353\n",
      "len_2_sigma_16_363\n",
      "len_2_sigma_16_373\n",
      "len_2_sigma_17_343\n",
      "len_2_sigma_17_353\n",
      "len_2_sigma_17_363\n",
      "len_2_sigma_17_373\n",
      "len_2_sigma_18_343\n",
      "len_2_sigma_18_353\n",
      "len_2_sigma_18_363\n",
      "len_2_sigma_18_373\n",
      "len_2_sigma_8_343\n",
      "len_2_sigma_8_353\n",
      "len_2_sigma_8_363\n",
      "len_2_sigma_8_373\n",
      "len_2_sigma_9_343\n",
      "len_2_sigma_9_353\n",
      "len_2_sigma_9_363\n",
      "len_2_sigma_9_373\n",
      "len_3_sigma_10_343\n",
      "len_3_sigma_10_353\n",
      "len_3_sigma_10_363\n",
      "len_3_sigma_10_373\n",
      "len_3_sigma_11_343\n",
      "len_3_sigma_11_353\n",
      "len_3_sigma_11_363\n",
      "len_3_sigma_11_373\n",
      "len_3_sigma_12_343\n",
      "len_3_sigma_12_353\n",
      "len_3_sigma_12_363\n",
      "len_3_sigma_12_373\n",
      "len_3_sigma_13_343\n",
      "len_3_sigma_13_353\n",
      "len_3_sigma_13_363\n",
      "len_3_sigma_13_373\n",
      "len_3_sigma_14_343\n",
      "len_3_sigma_14_353\n",
      "len_3_sigma_14_363\n",
      "len_3_sigma_14_373\n",
      "len_3_sigma_15_343\n",
      "len_3_sigma_15_353\n",
      "len_3_sigma_15_363\n",
      "len_3_sigma_15_373\n",
      "len_3_sigma_16_343\n",
      "len_3_sigma_16_353\n",
      "len_3_sigma_16_363\n",
      "len_3_sigma_16_373\n",
      "len_3_sigma_17_343\n",
      "len_3_sigma_17_353\n",
      "len_3_sigma_17_363\n",
      "len_3_sigma_17_373\n",
      "len_3_sigma_18_343\n",
      "len_3_sigma_18_353\n",
      "len_3_sigma_18_363\n",
      "len_3_sigma_18_373\n",
      "len_3_sigma_8_343\n",
      "len_3_sigma_8_353\n",
      "len_3_sigma_8_363\n",
      "len_3_sigma_8_373\n",
      "len_3_sigma_9_343\n",
      "len_3_sigma_9_353\n",
      "len_3_sigma_9_363\n",
      "len_3_sigma_9_373\n",
      "len_4_sigma_10_343\n",
      "len_4_sigma_10_353\n",
      "len_4_sigma_10_363\n",
      "len_4_sigma_10_373\n",
      "len_4_sigma_11_343\n",
      "len_4_sigma_11_353\n",
      "len_4_sigma_11_363\n",
      "len_4_sigma_11_373\n",
      "len_4_sigma_12_343\n",
      "len_4_sigma_12_353\n",
      "len_4_sigma_12_363\n",
      "len_4_sigma_12_373\n",
      "len_4_sigma_13_343\n",
      "len_4_sigma_13_353\n",
      "len_4_sigma_13_363\n",
      "len_4_sigma_13_373\n",
      "len_4_sigma_14_343\n",
      "len_4_sigma_14_353\n",
      "len_4_sigma_14_363\n",
      "len_4_sigma_14_373\n",
      "len_4_sigma_15_343\n",
      "len_4_sigma_15_353\n",
      "len_4_sigma_15_363\n",
      "len_4_sigma_15_373\n",
      "len_4_sigma_16_343\n",
      "len_4_sigma_16_353\n",
      "len_4_sigma_16_363\n",
      "len_4_sigma_16_373\n",
      "len_4_sigma_17_343\n",
      "len_4_sigma_17_353\n",
      "len_4_sigma_17_363\n",
      "len_4_sigma_17_373\n",
      "len_4_sigma_18_343\n",
      "len_4_sigma_18_353\n",
      "len_4_sigma_18_363\n",
      "len_4_sigma_18_373\n",
      "len_4_sigma_8_343\n",
      "len_4_sigma_8_353\n",
      "len_4_sigma_8_363\n",
      "len_4_sigma_8_373\n",
      "len_4_sigma_9_343\n",
      "len_4_sigma_9_353\n",
      "len_4_sigma_9_363\n",
      "len_4_sigma_9_373\n",
      "len_5_sigma_10_343\n",
      "len_5_sigma_10_353\n",
      "len_5_sigma_10_363\n",
      "len_5_sigma_10_373\n",
      "len_5_sigma_11_343\n",
      "len_5_sigma_11_353\n",
      "len_5_sigma_11_363\n",
      "len_5_sigma_11_373\n",
      "len_5_sigma_12_343\n",
      "len_5_sigma_12_353\n",
      "len_5_sigma_12_363\n",
      "len_5_sigma_12_373\n",
      "len_5_sigma_13_343\n",
      "len_5_sigma_13_353\n",
      "len_5_sigma_13_363\n",
      "len_5_sigma_13_373\n",
      "len_5_sigma_14_343\n",
      "len_5_sigma_14_353\n",
      "len_5_sigma_14_363\n",
      "len_5_sigma_14_373\n",
      "len_5_sigma_15_343\n",
      "len_5_sigma_15_353\n",
      "len_5_sigma_15_363\n",
      "len_5_sigma_15_373\n",
      "len_5_sigma_16_343\n",
      "len_5_sigma_16_353\n",
      "len_5_sigma_16_363\n",
      "len_5_sigma_16_373\n",
      "len_5_sigma_17_343\n",
      "len_5_sigma_17_353\n",
      "len_5_sigma_17_363\n",
      "len_5_sigma_17_373\n",
      "len_5_sigma_18_343\n",
      "len_5_sigma_18_353\n",
      "len_5_sigma_18_363\n",
      "len_5_sigma_18_373\n",
      "len_5_sigma_8_343\n",
      "len_5_sigma_8_353\n",
      "len_5_sigma_8_363\n",
      "len_5_sigma_8_373\n",
      "len_5_sigma_9_343\n",
      "len_5_sigma_9_353\n",
      "len_5_sigma_9_363\n",
      "len_5_sigma_9_373\n",
      "len_6_sigma_10_343\n",
      "len_6_sigma_10_353\n",
      "len_6_sigma_10_363\n",
      "len_6_sigma_10_373\n",
      "len_6_sigma_11_343\n",
      "len_6_sigma_11_353\n",
      "len_6_sigma_11_363\n",
      "len_6_sigma_11_373\n",
      "len_6_sigma_12_343\n",
      "len_6_sigma_12_353\n",
      "len_6_sigma_12_363\n",
      "len_6_sigma_12_373\n",
      "len_6_sigma_13_343\n",
      "len_6_sigma_13_353\n",
      "len_6_sigma_13_363\n",
      "len_6_sigma_13_373\n",
      "len_6_sigma_14_343\n",
      "len_6_sigma_14_353\n",
      "len_6_sigma_14_363\n",
      "len_6_sigma_14_373\n",
      "len_6_sigma_15_343\n",
      "len_6_sigma_15_353\n",
      "len_6_sigma_15_363\n",
      "len_6_sigma_15_373\n",
      "len_6_sigma_16_343\n",
      "len_6_sigma_16_353\n",
      "len_6_sigma_16_363\n",
      "len_6_sigma_16_373\n",
      "len_6_sigma_17_343\n",
      "len_6_sigma_17_353\n",
      "len_6_sigma_17_363\n",
      "len_6_sigma_17_373\n",
      "len_6_sigma_18_343\n",
      "len_6_sigma_18_353\n",
      "len_6_sigma_18_363\n",
      "len_6_sigma_18_373\n",
      "len_6_sigma_8_343\n",
      "len_6_sigma_8_353\n",
      "len_6_sigma_8_363\n",
      "len_6_sigma_8_373\n",
      "len_6_sigma_9_343\n",
      "len_6_sigma_9_353\n",
      "len_6_sigma_9_363\n",
      "len_6_sigma_9_373\n",
      "len_7_sigma_10_343\n",
      "len_7_sigma_10_353\n",
      "len_7_sigma_10_363\n",
      "len_7_sigma_10_373\n",
      "len_7_sigma_11_343\n",
      "len_7_sigma_11_353\n",
      "len_7_sigma_11_363\n",
      "len_7_sigma_11_373\n",
      "len_7_sigma_12_343\n",
      "len_7_sigma_12_353\n",
      "len_7_sigma_12_363\n",
      "len_7_sigma_12_373\n",
      "len_7_sigma_13_343\n",
      "len_7_sigma_13_353\n",
      "len_7_sigma_13_363\n",
      "len_7_sigma_13_373\n",
      "len_7_sigma_14_343\n",
      "len_7_sigma_14_353\n",
      "len_7_sigma_14_363\n",
      "len_7_sigma_14_373\n",
      "len_7_sigma_15_343\n",
      "len_7_sigma_15_353\n",
      "len_7_sigma_15_363\n",
      "len_7_sigma_15_373\n",
      "len_7_sigma_16_343\n",
      "len_7_sigma_16_353\n",
      "len_7_sigma_16_363\n",
      "len_7_sigma_16_373\n",
      "len_7_sigma_17_343\n",
      "len_7_sigma_17_353\n",
      "len_7_sigma_17_363\n",
      "len_7_sigma_17_373\n",
      "len_7_sigma_18_343\n",
      "len_7_sigma_18_353\n",
      "len_7_sigma_18_363\n",
      "len_7_sigma_18_373\n",
      "len_7_sigma_8_343\n",
      "len_7_sigma_8_353\n",
      "len_7_sigma_8_363\n",
      "len_7_sigma_8_373\n",
      "len_7_sigma_9_343\n",
      "len_7_sigma_9_353\n",
      "len_7_sigma_9_363\n",
      "len_7_sigma_9_373\n",
      "len_8_sigma_10_343\n",
      "len_8_sigma_10_353\n",
      "len_8_sigma_10_363\n",
      "len_8_sigma_10_373\n",
      "len_8_sigma_11_343\n",
      "len_8_sigma_11_353\n",
      "len_8_sigma_11_363\n",
      "len_8_sigma_11_373\n",
      "len_8_sigma_12_343\n",
      "len_8_sigma_12_353\n",
      "len_8_sigma_12_363\n",
      "len_8_sigma_12_373\n",
      "len_8_sigma_13_343\n",
      "len_8_sigma_13_353\n",
      "len_8_sigma_13_363\n",
      "len_8_sigma_13_373\n",
      "len_8_sigma_14_343\n",
      "len_8_sigma_14_353\n",
      "len_8_sigma_14_363\n",
      "len_8_sigma_14_373\n",
      "len_8_sigma_15_343\n",
      "len_8_sigma_15_353\n",
      "len_8_sigma_15_363\n",
      "len_8_sigma_15_373\n",
      "len_8_sigma_16_343\n",
      "len_8_sigma_16_353\n",
      "len_8_sigma_16_363\n",
      "len_8_sigma_16_373\n",
      "len_8_sigma_17_343\n",
      "len_8_sigma_17_353\n",
      "len_8_sigma_17_363\n",
      "len_8_sigma_17_373\n",
      "len_8_sigma_18_343\n",
      "len_8_sigma_18_353\n",
      "len_8_sigma_18_363\n",
      "len_8_sigma_18_373\n",
      "len_8_sigma_8_343\n",
      "len_8_sigma_8_353\n",
      "len_8_sigma_8_363\n",
      "len_8_sigma_8_373\n",
      "len_8_sigma_9_343\n",
      "len_8_sigma_9_353\n",
      "len_8_sigma_9_363\n",
      "len_8_sigma_9_373\n",
      "len_9_sigma_10_343\n",
      "len_9_sigma_10_353\n",
      "len_9_sigma_10_363\n",
      "len_9_sigma_10_373\n",
      "len_9_sigma_11_343\n",
      "len_9_sigma_11_353\n",
      "len_9_sigma_11_363\n",
      "len_9_sigma_11_373\n",
      "len_9_sigma_12_343\n",
      "len_9_sigma_12_353\n",
      "len_9_sigma_12_363\n",
      "len_9_sigma_12_373\n",
      "len_9_sigma_13_343\n",
      "len_9_sigma_13_353\n",
      "len_9_sigma_13_363\n",
      "len_9_sigma_13_373\n",
      "len_9_sigma_14_343\n",
      "len_9_sigma_14_353\n",
      "len_9_sigma_14_363\n",
      "len_9_sigma_14_373\n",
      "len_9_sigma_15_343\n",
      "len_9_sigma_15_353\n",
      "len_9_sigma_15_363\n",
      "len_9_sigma_15_373\n",
      "len_9_sigma_16_343\n",
      "len_9_sigma_16_353\n",
      "len_9_sigma_16_363\n",
      "len_9_sigma_16_373\n",
      "len_9_sigma_17_343\n",
      "len_9_sigma_17_353\n",
      "len_9_sigma_17_363\n",
      "len_9_sigma_17_373\n",
      "len_9_sigma_18_343\n",
      "len_9_sigma_18_353\n",
      "len_9_sigma_18_363\n",
      "len_9_sigma_18_373\n",
      "len_9_sigma_8_343\n",
      "len_9_sigma_8_353\n",
      "len_9_sigma_8_363\n",
      "len_9_sigma_8_373\n",
      "len_9_sigma_9_343\n",
      "len_9_sigma_9_353\n",
      "len_9_sigma_9_363\n",
      "len_9_sigma_9_373\n",
      "文件数: 836\n",
      "数据库内容 OK 👌🏻\n"
     ]
    }
   ],
   "source": [
    "# 检验 hdf5 GA结构数据库 存在\n",
    "if Path(Conf.path_to_grid_DataBase).exists():\n",
    "    print(\"数据库存在 ✅\")\n",
    "    # 检查 hdf5 GA结构数据库 内含矩阵数量\n",
    "    if check_hdf5_content(Conf.path_to_grid_DataBase) == int(len(Conf.len_list) * len( Conf.sigma_list) * len( Conf.temp_list)):\n",
    "        print(\"数据库内容 OK 👌🏻\")\n",
    "        # 删除临时文件\n",
    "        shutil.rmtree(Conf.path_to_temp_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4lammps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
