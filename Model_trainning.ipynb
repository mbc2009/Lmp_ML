{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbc2009/Lmp_ML/blob/main/Model_trainning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Enviornment Initialization"
      ],
      "metadata": {
        "id": "5LSSxtHN4uqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "\n",
        "# remove unnecessary\n",
        "rm -rf *\n",
        "\n",
        "# update pip\n",
        "python -m pip install --upgrade pip\n",
        "\n",
        "# install package\n",
        "pip install opencv-python pillow\n",
        "pip install segmentation_models_pytorch\n",
        "pip install -q kaggle\n",
        "pip install dropbox\n",
        "pip install scikit-image\n",
        "pip install pandas openpyxl"
      ],
      "metadata": {
        "id": "VkjBZjG7RWAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic import\n",
        "import  os, sys, time, math, random, math, psutil, h5py, re\n",
        "from    concurrent.futures      import ThreadPoolExecutor\n",
        "from    typing                  import  List, Tuple\n",
        "from    dropbox                 import  Dropbox\n",
        "from    tqdm                    import  tqdm\n",
        "from    mpl_toolkits.mplot3d    import  Axes3D\n",
        "from    matplotlib              import  pyplot      as plt\n",
        "import  numpy                                       as np\n",
        "import  pandas                                      as pd\n",
        "import  zipfile\n",
        "import  warnings\n",
        "import  shutil\n",
        "import  joblib\n",
        "\n",
        "from    sklearn.preprocessing   import MinMaxScaler\n",
        "from    skimage                 import  io\n",
        "from    scipy                   import  interpolate\n",
        "from    scipy.interpolate       import  RegularGridInterpolator\n",
        "from    scipy.ndimage           import  generic_filter, rotate\n",
        "from    PIL                     import  Image\n",
        "\n",
        "import  torch\n",
        "from    torch                   import  nn\n",
        "from    torch.nn                import  functional  as F\n",
        "import  torch.optim                                 as optim\n",
        "import  torchvision.transforms.functional           as TF\n",
        "from    torch.utils.data        import  Dataset, DataLoader, TensorDataset, random_split, Subset\n",
        "from    torchvision             import  transforms, models\n",
        "from    torchvision.transforms  import  *\n",
        "import  kagglehub"
      ],
      "metadata": {
        "id": "ERcbfqGSXFT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check hardware\n",
        "print(f\"CPU core #:\\t{os.cpu_count()}\")\n",
        "print(f\"CPU threads #:\\t{psutil.cpu_count(logical=True)}\")\n",
        "print(f\"Total memory:\\t\\t{psutil.virtual_memory().total / (1024**3):.2f} GB\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    print(f\"available GPU #:\\t{gpu_count}\")\n",
        "    for i in range(gpu_count):\n",
        "        gpu_name = torch.cuda.get_device_name(i)\n",
        "        print(f\"GPU {i+1}:\\t\\t{gpu_name}\")\n",
        "else:\n",
        "    print(\"No available GPU\")"
      ],
      "metadata": {
        "id": "AnJ7zHLJxbro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configuration"
      ],
      "metadata": {
        "id": "GBCVteWiX60Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Confuration():\n",
        "  # define paths to directory\n",
        "  home_dir                = os.path.expanduser(\"~\")\n",
        "  working_dir             = os.path.join(os.getcwd(),'Lmp_ML')\n",
        "  DataBase_dir            = os.path.join(working_dir,'DataBase')\n",
        "  DB_version              = 5\n",
        "  DB_3D_Grids_density     = 128\n",
        "  DB_3D_Grids_path        = os.path.join(DataBase_dir, f'{DB_version}', f'3D_Grids_{DB_3D_Grids_density}.h5') # TODO: choose database version, here ver=4\n",
        "  DB_Excel_path           = os.path.join(working_dir,  f'LmpGP.xlsx')                                         # TODO: choose database version, here ver=4\n",
        "\n",
        "  # dataset\n",
        "  DB_items                = ['temp\\n(k)',\n",
        "                             'pore_radius\\n(A)',\n",
        "                             'density\\n(g/cm^3)']\n",
        "\n",
        "  # debug\n",
        "  dev_mode                = True\n",
        "\n",
        "conf = Confuration()"
      ],
      "metadata": {
        "id": "FW2lJM8WXWUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import code from git hub\n",
        "!git clone https://github.com/mbc2009/Lmp_ML"
      ],
      "metadata": {
        "id": "nla41gbQQuJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make directory\n",
        "os.makedirs(conf.DataBase_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "pjO4Z6FqrZgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download\n",
        "original_path = kagglehub.dataset_download(\"mbc2009/heat-and-mass-transfer\",force_download=True)\n",
        "shutil.move(original_path, conf.DataBase_dir)"
      ],
      "metadata": {
        "id": "z_1Gn-B1mOa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Functions and Classes"
      ],
      "metadata": {
        "id": "cJevHupf53MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_hdf5_content(file_path:str,PrintStrcut=False)->int:\n",
        "  '''\n",
        "  check the content (name, quantity) of hdf5 file\n",
        "  input:\n",
        "    file_path: the path of hdf5 file\n",
        "    PrintStrcut: print the structure of hdf5 file\n",
        "  return:\n",
        "    the name and quantity of variables in hdf5 file\n",
        "  '''\n",
        "  # 初始化数据集计数器\n",
        "  dataset_count = 0\n",
        "\n",
        "  # 定义一个内部函数用于遍历 HDF5 文件内部\n",
        "  def count_datasets(name, obj):\n",
        "        nonlocal dataset_count\n",
        "        if isinstance(obj, h5py.Dataset):  # 判断是否为数据集\n",
        "            dataset_count += 1\n",
        "        elif isinstance(obj, h5py.Group):  # 判断是否为组\n",
        "            pass  # 如果是组，不计数\n",
        "\n",
        "  with h5py.File(file_path, \"r\") as h5f:\n",
        "\n",
        "        # 遍历文件内容以计数\n",
        "        h5f.visititems(count_datasets)\n",
        "\n",
        "        # 打印所有内变量名字\n",
        "        if PrintStrcut:\n",
        "          print(f\"文件结构:\")\n",
        "          h5f.visit(print)\n",
        "\n",
        "  print(f'文件数: {dataset_count}')\n",
        "\n",
        "  return dataset_count # 文件数"
      ],
      "metadata": {
        "id": "YcLDL7kX52K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Prepare Data Base"
      ],
      "metadata": {
        "id": "XNATVGXi3qJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Prepare Excel Data Base"
      ],
      "metadata": {
        "id": "xdsVuq64sDWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Excel data into pandas data frame\n",
        "df = pd.read_excel(conf.DB_Excel_path, engine=\"openpyxl\")"
      ],
      "metadata": {
        "id": "8G5we5wnsDCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 打印形状\n",
        "  print(df.shape)\n",
        "\n",
        "  # 读取列名\n",
        "  print(df.columns)"
      ],
      "metadata": {
        "id": "mjSiqXTlhZYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 筛选列名对应列\n",
        "  df = df.loc[:, ['len\\n(A)', 'sigma\\n(A)', 'temp\\n(k)', 'flux\\n(L/m^2/h)', 'density\\n(g/cm^3)']]"
      ],
      "metadata": {
        "id": "lAes1TjFg59q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_from_pandas(len_i: int, sigma_i: int, temp_i: int, items: List[str], df: pd.DataFrame) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    根据 len_i, sigma_i, temp_i 在 pandas DataFrame 中查找指定 items，并返回一个 PyTorch Tensor。\n",
        "\n",
        "    Args:\n",
        "        len_i (int):        目标 len 值\n",
        "        sigma_i (int):      目标 sigma 值\n",
        "        temp_i (int):       目标 temp 值\n",
        "        items (List[str]):  需要提取的列名列表\n",
        "        df (pd.DataFrame):  数据源 Pandas DataFrame\n",
        "\n",
        "    Returns:\n",
        "        Optional[torch.Tensor]: 若找到数据，则返回一个 Float32 类型的 PyTorch Tensor，否则返回 None。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 筛选符合条件的行，并提取多个列\n",
        "        item_values = df.loc[\n",
        "            (df[\"len\\n(A)\"] == len_i) &\n",
        "            (df[\"sigma\\n(A)\"] == sigma_i) &\n",
        "            (df[\"temp\\n(k)\"] == temp_i),\n",
        "            items\n",
        "        ]\n",
        "\n",
        "        # 确保只有一行数据，转换为 Tensor\n",
        "        if not item_values.empty:\n",
        "            tensor_values = torch.tensor(item_values.values.flatten(), dtype=torch.float32)\n",
        "            return tensor_values\n",
        "        else:\n",
        "            return None  # 没有匹配数据时返回 None\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"列名错误: {e}\")\n",
        "        return None\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"数据转换错误: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ZXqnsln3g0nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 使用示例\n",
        "  items = fetch_from_pandas(len_i= 2, sigma_i=8, temp_i=373, items=['density\\n(g/cm^3)'], df=df)\n",
        "  print(items[0].item())"
      ],
      "metadata": {
        "id": "3GTSxD6GlDtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.Check grid data base"
      ],
      "metadata": {
        "id": "DJ1Jn8Oo4qm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 查看hdf5文件内容\n",
        "  num_grids = check_hdf5_content(conf.DB_3D_Grids_path,PrintStrcut=False)"
      ],
      "metadata": {
        "id": "OinYQCkb46xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 查看单个数据点\n",
        "  DB_3D_Grids = h5py.File(conf.DB_3D_Grids_path, \"r\")\n",
        "  GA          = DB_3D_Grids[f\"len_{2}_sigma_{18}_{343}\"][:]\n",
        "  print(f'矩阵形状:   {GA.shape}')\n",
        "  print(f'矩阵最大值: {np.max(GA)}')\n",
        "  print(f'矩阵最小值: {np.min(GA)}')\n",
        "  print(f\"矩阵 GA 中 {np.max(GA)} 的数量：{np.count_nonzero(GA == np.max(GA)) }\")"
      ],
      "metadata": {
        "id": "VD-kiwaI6UGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 可视化函数\n",
        "def plot_3D_Grid(matrix_3d):\n",
        "    \"\"\"\n",
        "    绘制三维点阵的三视图（正视图、侧视图、俯视图）。\n",
        "\n",
        "    Args:\n",
        "        matrix_3d (numpy.ndarray): 三维点阵数据。\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # 创建图形和坐标轴\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # 俯视图 (X-Y 平面)\n",
        "    axes[0].imshow(np.sum(matrix_3d, axis=0), cmap='viridis')  # 沿 Z 轴求和\n",
        "    axes[0].set_title('Top View (X-Y)')\n",
        "    axes[0].set_xlabel('X')\n",
        "    axes[0].set_ylabel('Y')\n",
        "\n",
        "    # 正视图 (Z-X 平面)\n",
        "    axes[1].imshow(np.sum(matrix_3d, axis=1), cmap='viridis')  # 沿 Y 轴求和\n",
        "    axes[1].set_title('Front View (Z-X)')\n",
        "    axes[1].set_xlabel('Z')\n",
        "    axes[1].set_ylabel('X')\n",
        "\n",
        "    # 侧视图 (Z-Y 平面)\n",
        "    axes[2].imshow(np.sum(matrix_3d, axis=2), cmap='viridis')  # 沿 X 轴求和\n",
        "    axes[2].set_title('Side View (Z-Y)')\n",
        "    axes[2].set_xlabel('Z')\n",
        "    axes[2].set_ylabel('Y')\n",
        "\n",
        "    # 显示图形\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "X0k9E-fD9Rv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  plot_3D_Grid(GA)  # 将 GA 替换为你的三维点阵数据"
      ],
      "metadata": {
        "id": "Idw6WbDn_8JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3.Home-brewing dataset"
      ],
      "metadata": {
        "id": "sh83ztK7I5gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myDataBase(Dataset):\n",
        "    def __init__(self,\n",
        "                 hdf5_3D_Grids_file_path:str,\n",
        "                 excel_Performance_and_Properties_file_path:str):\n",
        "        '''\n",
        "        name:  'len_{i}_sigma_{j}_temp_{k}'\n",
        "        label: [len_i, sigma_i, temp_i], type: pytorch tensor\n",
        "        structure: 3D grid, type: pytorch tensor\n",
        "        '''\n",
        "        ## GRID\n",
        "        # 3D grids (h5py file)\n",
        "        self.grids_hdf5     = h5py.File(hdf5_3D_Grids_file_path, 'r')\n",
        "        # Sorted name list of all GA structures (h5py file)\n",
        "        self.data_NameList  = self.sort_NameList((self.grids_hdf5.keys()))\n",
        "\n",
        "        ## EXCEL\n",
        "        # Performance & Properties (Excel => PD)\n",
        "        self.PnP_pd = pd.read_excel(excel_Performance_and_Properties_file_path, engine=\"openpyxl\")\n",
        "        self.PnP_pd = self.PnP_pd\n",
        "\n",
        "        # Normalize PD file\n",
        "        self.scaler           = MinMaxScaler()\n",
        "        self.PnP_pd_selected  = self.PnP_pd[conf.DB_items].copy()                # Select desired columns from the original DataFrame\n",
        "        self.PnP_pd_scaled    = self.scaler.fit_transform(self.PnP_pd_selected)  # Scale the selected data\n",
        "        self.PnP_pd_scaled    = pd.DataFrame(self.PnP_pd_scaled,                 # Convert to DataFrame\n",
        "                                          columns=self.PnP_pd_selected.columns)\n",
        "\n",
        "\n",
        "        joblib.dump(self.scaler, \"scaler.pkl\")  # 保存 scaler（用于推理时 inverse_transform 反归一化）\n",
        "        print('Scaler Saved')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_NameList)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ## 1. Index ##\n",
        "        # 解析: index -> str\n",
        "        name_i      = self.data_NameList[index]\n",
        "\n",
        "        # 转换: str -> list [len_i, sigma_i, temp_i] -> tensor\n",
        "        label_i     = self.extract_label_from_key(name_i)\n",
        "\n",
        "        ## 2. GRIDS ##\n",
        "        # 提取 (hdf5 => np.ndarray)\n",
        "        grid_i      = self.grids_hdf5[name_i][:]\n",
        "        # 转换: Grids (np.ndarray -> PyTorch tensor)\n",
        "        grid_i      = torch.from_numpy(grid_i)\n",
        "\n",
        "        ## 3. EXCEL ##\n",
        "        # find row index\n",
        "        pd_idx   = self.seek_idx_from_pandas(len_i=label_i[0],\n",
        "                                            sigma_i=label_i[1],\n",
        "                                            temp_i=label_i[2],\n",
        "                                            items=conf.DB_items,\n",
        "                                            df=self.PnP_pd)\n",
        "        # Pandas => tensor ([item1,item2,item3...]\n",
        "        items_i  = self.PnP_pd_scaled.iloc[pd_idx]\n",
        "        items_i  = torch.tensor(items_i.values, dtype=torch.float32)\n",
        "\n",
        "        ## 4. 返回\n",
        "        return torch.tensor(label_i), grid_i, items_i\n",
        "\n",
        "    def close(self):\n",
        "         # 关闭h5文件，防止损坏\n",
        "        self.grids_hdf5.close()\n",
        "\n",
        "    def extract_label_from_key(self, name:str):\n",
        "        # 解析数据点名称为三维张量\n",
        "        len_val   = int(name.split('_')[1])\n",
        "        sigma_val = int(name.split('_')[3])\n",
        "        temp_val  = int(name.split('_')[-1])\n",
        "        label_i   = [len_val, sigma_val, temp_val]\n",
        "        return label_i\n",
        "\n",
        "    def seek_idx_from_pandas(self, len_i:int, sigma_i:int, temp_i:int, items:List[str], df: pd.DataFrame) -> torch.Tensor:\n",
        "        # ... (other parts of the function remain the same) ...\n",
        "\n",
        "        try:\n",
        "            item_idx = df.loc[\n",
        "                (df[\"len\\n(A)\"]   == len_i) &\n",
        "                (df[\"sigma\\n(A)\"] == sigma_i) &\n",
        "                (df[\"temp\\n(k)\"]  == temp_i),\n",
        "                items\n",
        "            ].index\n",
        "\n",
        "            # Check if item_idx is empty before accessing element 0\n",
        "            if len(item_idx) > 0:\n",
        "                return item_idx[0]\n",
        "            else:\n",
        "                # Handle the case where no matching rows are found\n",
        "                print(f\"Warning: No matching rows found for len={len_i}, sigma={sigma_i}, temp={temp_i}: {item_idx}\")\n",
        "                return -1 # or raise ValueError(\"No matching rows found\")\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"列名错误: {e}\")\n",
        "            return None\n",
        "\n",
        "        except ValueError as e:\n",
        "            print(f\"数据转换错误: {e}\")\n",
        "            return None\n",
        "\n",
        "    def sort_NameList(self, strings:str):\n",
        "        # 数据点列表名称排序\n",
        "        def key_func(s):\n",
        "            match = re.match(r\"len_(\\d+)_sigma_(\\d+)_(\\d+)\", s)  # 提取数字\n",
        "            if match:\n",
        "                len_val, sigma_val, temp_val = map(int, match.groups())\n",
        "                return (len_val, sigma_val, -temp_val)  # 第三个数字取反，实现降序\n",
        "            else:\n",
        "                return (float('inf'), float('inf'), float('-inf'))  # 处理不匹配的情况\n",
        "        return sorted(strings, key=key_func)  # 排序\n"
      ],
      "metadata": {
        "id": "LoTTY1WaJE6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 创建\n",
        "  dataset = myDataBase(conf.DB_3D_Grids_path,conf.DB_Excel_path)\n",
        "\n",
        "  # 读取\n",
        "  label_i, grid_i, items_i  = dataset[0]\n",
        "  dataset.close() # 关闭读取\n",
        "\n",
        "  # 打印\n",
        "  print(f'{label_i}\\t\\t{type(label_i)}\\n{grid_i.shape}\\t{type(grid_i)}\\n{items_i}\\t{type(items_i)}')"
      ],
      "metadata": {
        "id": "ZjIttRqEnFhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  print(dataset.PnP_pd)#.to_string())"
      ],
      "metadata": {
        "id": "VF-TltFg9bP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  print(dataset.PnP_pd_scaled.to_string())"
      ],
      "metadata": {
        "id": "yKDUJtuZxx8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 查看文件名列表\n",
        "  # 长度\n",
        "  print(len(dataset.data_NameList))\n",
        "\n",
        "  # 内容\n",
        "  for i in dataset.data_NameList:\n",
        "      print(i)\n",
        "  dataset.close() # 关闭读取"
      ],
      "metadata": {
        "id": "LKuL5MuG7XVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Data augmentation"
      ],
      "metadata": {
        "id": "w7SXUvb6Bkb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_3D_Grid(matrix_3d: np.ndarray, angle_degrees: float):\n",
        "    \"\"\"\n",
        "    绕穿过 x-y 平面的中心点且平行于 z 轴的轴旋转三维矩阵。\n",
        "\n",
        "    Args:\n",
        "        matrix_3d (numpy.ndarray): 要旋转的三维矩阵。\n",
        "        angle_degrees (float): 旋转角度（以度为单位，默认逆时针）。\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: 旋转后的三维矩阵。\n",
        "    \"\"\"\n",
        "    rotated_matrix = rotate(matrix_3d,\n",
        "                            angle=-angle_degrees,  # 顺时针旋转\n",
        "                            axes=(1, 2),  # 旋转 x-y 平面，即绕 z 轴旋转\n",
        "                            reshape=False,\n",
        "                            order=0,\n",
        "                            mode='constant',\n",
        "                            cval=0)\n",
        "    return rotated_matrix\n",
        "\n",
        "def multi_threaded_rotation(matrix_3d: np.ndarray):\n",
        "    \"\"\"\n",
        "    并行计算 90°, 180°, 270° 三种旋转后的 3D 矩阵。\n",
        "\n",
        "    Args:\n",
        "        matrix_3d (numpy.ndarray): 要旋转的三维矩阵。\n",
        "\n",
        "    Returns:\n",
        "        dict: 包含 90°, 180°, 270° 旋转后的矩阵。\n",
        "    \"\"\"\n",
        "    angles          = [90, 180, 270]\n",
        "    rotated_results = {}\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        results = executor.map(rotate_3D_Grid, [matrix_3d]*3, angles)\n",
        "\n",
        "    # 存储旋转后的矩阵\n",
        "    for angle, rotated_matrix in zip(angles, results):\n",
        "        rotated_results[f\"rotate_{angle}\"] = rotated_matrix\n",
        "\n",
        "    return rotated_results"
      ],
      "metadata": {
        "id": "7un57V8nBiPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # simple case\n",
        "  GA = np.asarray([\n",
        "                  [[2,3,4],  # z = 3\n",
        "                  [1,2,3],\n",
        "                  [0,1,2]],\n",
        "                  [[2,2,2],   # z = 3\n",
        "                  [2,2,2],\n",
        "                  [2,2,2]],\n",
        "                  [[1,1,1],   # z = 2\n",
        "                  [1,1,1],\n",
        "                  [1,1,1]],\n",
        "                  [[0,0,0],   # z = 1\n",
        "                  [0,0,0],\n",
        "                  [0,0,0]],\n",
        "                  [[0,0,0],   # z = 0\n",
        "                  [0,0,0],\n",
        "                  [0,0,0]]]\n",
        "                  )\n",
        "\n",
        "  # 示例测试\n",
        "  rotated_matrices = multi_threaded_rotation(GA)\n",
        "\n",
        "  # 获取旋转后的结果\n",
        "  rotate_90  = rotated_matrices[\"rotate_90\"]\n",
        "  rotate_180 = rotated_matrices[\"rotate_180\"]\n",
        "  rotate_270 = rotated_matrices[\"rotate_270\"]\n",
        "\n",
        "  # 输出形状检查\n",
        "  print(rotate_90.shape, rotate_180.shape, rotate_270.shape)\n",
        "\n",
        "  # plot\n",
        "  plot_3D_Grid(GA)\n",
        "  plot_3D_Grid(rotate_90)\n",
        "  plot_3D_Grid(rotate_180)\n",
        "  plot_3D_Grid(rotate_270)"
      ],
      "metadata": {
        "id": "F60zIc1FCkJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  DB_3D_Grids = h5py.File(conf.DB_3D_Grids_path, \"r\")\n",
        "  GA          = DB_3D_Grids[f\"len_{2}_sigma_{18}_{343}\"][:]\n",
        "\n",
        "\n",
        "  # 示例测试\n",
        "  rotated_matrices = multi_threaded_rotation(GA)\n",
        "\n",
        "  # 获取旋转后的结果\n",
        "  rotate_90  = rotated_matrices[\"rotate_90\"]\n",
        "  rotate_180 = rotated_matrices[\"rotate_180\"]\n",
        "  rotate_270 = rotated_matrices[\"rotate_270\"]\n",
        "\n",
        "  # 输出形状检查\n",
        "  print(rotate_90.shape, rotate_180.shape, rotate_270.shape)\n",
        "\n",
        "  # plot\n",
        "  plot_3D_Grid(GA)\n",
        "  plot_3D_Grid(rotate_90)\n",
        "  plot_3D_Grid(rotate_180)\n",
        "  plot_3D_Grid(rotate_270)"
      ],
      "metadata": {
        "id": "jAmVF9uaQqzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RotatedDataBase(myDataBase):\n",
        "    \"\"\"\n",
        "    3D 矩阵旋转数据集，返回 90°, 180°, 270° 旋转后的矩阵。\n",
        "    \"\"\"\n",
        "    def __init__(self, base_dataset):\n",
        "        \"\"\"\n",
        "        初始化数据集。\n",
        "\n",
        "        Args:\n",
        "            data_list (list of np.ndarray): 原始 3D 矩阵列表，每个矩阵 shape=(400,400,400)。\n",
        "        \"\"\"\n",
        "        self.base_dataset     = base_dataset                # 原始数据集\n",
        "        self.rotation_angles  = [0, 90, 180, 270]           # 旋转角度\n",
        "        self.num_rotations    = len(self.rotation_angles)   # 旋转次数\n",
        "        #self.data_NameList    = base_dataset.data_NameList  # 数据点列表名称\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        数据集大小\n",
        "        \"\"\"\n",
        "        return int(len(self.base_dataset)*(self.num_rotations))\n",
        "\n",
        "    def __getitem__(self, new_idx):\n",
        "        \"\"\"\n",
        "        获取数据并返回旋转后的4个版本\n",
        "        Returns:\n",
        "            dict: {\"original\":   原始 3D 矩阵,\n",
        "                   \"rotate_90\":  顺时旋转 90°,\n",
        "                   \"rotate_180\": 顺时旋转 180°,\n",
        "                   \"rotate_270\": 顺时旋转 270°}\n",
        "        \"\"\"\n",
        "        # 计算index\n",
        "        rotation_idx    = new_idx %  (self.num_rotations)  # index within the rotation group\n",
        "        original_idx    = new_idx // (self.num_rotations)  # index in the oringal base dataset\n",
        "\n",
        "        # 原始矩阵\n",
        "        label_i, grid_i, items_i  = self.base_dataset[original_idx]\n",
        "\n",
        "        # 旋转\n",
        "        rotated_grid_i = rotate_3D_Grid(matrix_3d=grid_i, angle_degrees=self.rotation_angles[rotation_idx])\n",
        "\n",
        "        # 确保转换为 float32 的 PyTorch Tensor\n",
        "        rotated_grid_i = torch.from_numpy(rotated_grid_i).to(torch.float32)\n",
        "\n",
        "        # 添加 channel 维度 (channels, depth, height, width) for 3D CNN\n",
        "        #rotated_grid_i = rotated_grid_i.unsqueeze(0)\n",
        "\n",
        "        # 返回\n",
        "        return  label_i, rotated_grid_i, items_i"
      ],
      "metadata": {
        "id": "V9gz6eb3XudQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if conf.dev_mode:\n",
        "  # 创建\n",
        "  dataset = myDataBase(conf.DB_3D_Grids_path,conf.DB_Excel_path)\n",
        "\n",
        "  # Augmentation\n",
        "  rotated_dataset = RotatedDataBase(dataset)\n",
        "\n",
        "  for idx in [0,1,2,3]:\n",
        "    idx += (11*4)\n",
        "    print(idx)\n",
        "    label_i, grid_i, items_i = rotated_dataset[idx]\n",
        "\n",
        "    print(f'check-{dataset.data_NameList[idx//4]}')\n",
        "\n",
        "    print(label_i, grid_i.shape, items_i)\n",
        "    print(type(grid_i))"
      ],
      "metadata": {
        "id": "kdEF5NDjhXTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader speed test\n",
        "if False:\n",
        "\n",
        "  def load_data_item(dataset, index):\n",
        "      \"\"\"\n",
        "      加载单个数据项\n",
        "      \"\"\"\n",
        "      _, _, _ = dataset[index]\n",
        "\n",
        "\n",
        "  def calculate_loading_time_multithreaded(dataset, num_threads=4):\n",
        "      \"\"\"使用多线程计算加载数据集所需的时间。\"\"\"\n",
        "      start_time = time.time()\n",
        "\n",
        "      with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "          # 创建任务列表，每个任务加载一个数据项\n",
        "          tasks = [executor.submit(load_data_item, dataset, i) for i in range(len(dataset))]\n",
        "\n",
        "          # 使用 tqdm 显示进度条，并等待所有任务完成\n",
        "          for _ in tqdm(tasks, total=len(tasks), desc=\"多线程加载数据集...\"):\n",
        "              _.result()  # 获取任务结果，以确保任务已完成\n",
        "\n",
        "      end_time = time.time()\n",
        "      total_time = end_time - start_time\n",
        "\n",
        "      return total_time\n",
        "\n",
        "\n",
        "  # 创建数据集\n",
        "  dataset = myDataBase(conf.DB_3D_Grids_path, conf.DB_Excel_path)\n",
        "  rotated_dataset = RotatedDataBase(dataset)\n",
        "\n",
        "  # 计算并打印加载时间\n",
        "  loading_time = calculate_loading_time_multithreaded(rotated_dataset, num_threads=int(psutil.cpu_count(logical=True)))\n",
        "  print(f\"使用多线程加载整个 rotated_dataset 所需时间：{loading_time:.2f} 秒\")"
      ],
      "metadata": {
        "id": "-SYAs_dqq1RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Model Preparation"
      ],
      "metadata": {
        "id": "G_pgJxC031wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Simple3DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Simple3DCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1)   # 维度不变\n",
        "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)  # 维度不变\n",
        "        self.pool  = nn.MaxPool3d(2, 2)                 # 2x2x2 池化，尺寸减半\n",
        "        self.fc1   = nn.Linear(32 * 32 * 32 * 32, 128)  # 调整输入维度\n",
        "        self.fc2   = nn.Linear(128, 2)                  # 输出2个值\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 128x128x128 -> 64x64x64\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 64x64x64 -> 32x32x32\n",
        "        x = x.view(-1, 32 * 32 * 32 * 32)     # 修改 reshape 维度\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1Kj_vy7k39wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Improved3DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Improved3DCNN, self).__init__()\n",
        "        self.conv1  = nn.Conv3d(1,  16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2  = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool   = nn.MaxPool3d(2, 2)        # 2x2x2 池化，尺寸减半\n",
        "\n",
        "        self.fc1          = nn.Linear(32 * 32 * 32 * 32, 128)               # CNN 提取的特征\n",
        "        self.transformer  = TransformerEncoderLayer(d_model=128, nhead=4)   # Transformer 处理特征\n",
        "        self.fc2          = nn.Linear(128 + 1, 64)                          # 只加入 temp_i（1 维）\n",
        "        self.fc3          = nn.Linear(64, 2)                                # 输出2个值\n",
        "\n",
        "    def forward(self, x, tensor_i):\n",
        "        x = self.pool(F.relu(self.conv1(x.float())))  # 128³ -> 64³\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 64³ -> 32³\n",
        "        x = x.view(-1, 32 * 32 * 32 * 32)     # 展平\n",
        "\n",
        "        x = F.relu(self.fc1(x))             # fc1 out: CNN 特征提取\n",
        "        x = x.unsqueeze(0)                  # Transformer 输入需要 (seq_len, batch, feature_dim)\n",
        "        x = self.transformer(x)             # 通过 Transformer 处理\n",
        "        x = x.squeeze(0)                    # 恢复 batch 维度\n",
        "\n",
        "        temp_i  = tensor_i.unsqueeze(1)            # 只取 temp_i，形状变为 (batch_size, 1)\n",
        "        x       = torch.cat((x, temp_i), dim=1)    # 拼接 temp_i\n",
        "\n",
        "        x = F.relu(self.fc2(x))             # fc2 out: relu\n",
        "        x = self.fc3(x)                     # fc3 out: 输出最终结果\n",
        "        return x\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=128, nhead=4, dim_feedforward=256, dropout=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.transformer   = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.transformer(x)"
      ],
      "metadata": {
        "id": "oBaiZYQWg-vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Load Data"
      ],
      "metadata": {
        "id": "AtNcOFfAj9sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 设定训练集和测试集比例\n",
        "train_ratio = 0.8  # 80% 训练集, 20% 测试集\n",
        "\n",
        "# 读取原始数据\n",
        "dataset = myDataBase(conf.DB_3D_Grids_path, conf.DB_Excel_path)\n",
        "\n",
        "# 计算划分数量\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "test_size  = len(dataset) - train_size\n",
        "\n",
        "# 先在 原始数据 上进行划分\n",
        "indices = list(range(len(dataset)))  # 原始数据索引\n",
        "train_indices, test_indices = random_split(indices, [train_size, test_size])\n",
        "\n",
        "# 创建训练集和测试集的 Subset\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset  = Subset(dataset, test_indices)"
      ],
      "metadata": {
        "id": "ax_wFWLmkA9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 仅增强训练集\n",
        "train_dataset_augmented = RotatedDataBase(train_dataset)"
      ],
      "metadata": {
        "id": "EiV_0q4Tnnhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成 DataLoader\n",
        "train_loader = DataLoader(train_dataset_augmented, batch_size=64, shuffle=True, num_workers=psutil.cpu_count(logical=True))\n",
        "test_loader  = DataLoader(test_dataset,            batch_size=64, shuffle=False, num_workers=psutil.cpu_count(logical=True))\n",
        "\n",
        "print(f\"训练集大小: {len(train_dataset_augmented)}, 测试集大小: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "qhnW64cxnpSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Model Trainning"
      ],
      "metadata": {
        "id": "QMAxND_E7Rb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialization\n",
        "device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model           = Improved3DCNN().to(device)\n",
        "criterion       = nn.MSELoss()\n",
        "\n",
        "torch.cuda.empty_cache() # 清理缓存\n",
        "\n",
        "def model_train(num_epochs:int, learning_rate:float):\n",
        "  model.train() # 训练模式\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  for epoch in range(num_epochs):\n",
        "      running_loss = 0.0\n",
        "      for label, grid, items in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "          label, grid, items = label.to(device), grid.to(device), items.to(device)\n",
        "          grid  = grid.unsqueeze(1)  # 添加 channel 维度 (channels, depth, height, width) for 3D CNN\n",
        "          optimizer.zero_grad()      # 清零 梯度\n",
        "          output = model(grid, items[:, 0])  # TODO: 确保 输入grid + temp_i, 前向传播\n",
        "          loss   = criterion(output, items[:, 1:]) # TODO: 确保 输入 temp_i 以后的\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "      print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "BJAUxE_xlVeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainning: stage-1\n",
        "model_train(num_epochs=10,learning_rate=0.0004)\n",
        "\n",
        "# save\n",
        "torch.save(model.state_dict(), \"3d_cnn_model.pth\")\n",
        "print(\"✅ 模型训练完成，已保存！\")"
      ],
      "metadata": {
        "id": "2QCH02r77Q14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trainning: stage-2\n",
        "# load model\n",
        "model.load_state_dict(torch.load(\"3d_cnn_model.pth\"))\n",
        "\n",
        "# train\n",
        "model_train(num_epochs=5,learning_rate=0.0001)\n",
        "\n",
        "# 再次保存模型\n",
        "torch.save(model.state_dict(), \"3d_cnn_model_v2.pth\")\n",
        "print(\"✅ 继续训练完成，已保存为 `3d_cnn_model_v2.pth`\")"
      ],
      "metadata": {
        "id": "pO-qvY5e2dDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Model Evaluation"
      ],
      "metadata": {
        "id": "YvNzmgG3nLFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载模型\n",
        "model = Improved3DCNN().to(device)                        # Create an instance of your model\n",
        "model.load_state_dict(torch.load('3d_cnn_model_v2.pth'))  # Load the saved state_dict\n",
        "model.eval()                                              # Set the model to evaluation mode\n",
        "\n",
        "# 用于存储预测值和真实值\n",
        "predictions_scaled   = []\n",
        "actual_values_scaled = []\n",
        "\n",
        "# 用于存储总的损失\n",
        "total_loss    = 0.0\n",
        "criterion     = nn.MSELoss()\n",
        "\n",
        "# Replace epoch with a placeholder or remove it entirely\n",
        "with torch.no_grad():\n",
        "    for label, grid, items in tqdm(test_loader, desc=f\"Evaluating...\"): # Changed description\n",
        "        label, grid, items = label.to(device), grid.to(device), items.to(device)\n",
        "        grid    = grid.unsqueeze(1)               # 添加 channel 维度 (channels, depth, height, width) for 3D CNN\n",
        "        output  = model(grid, items[:, 0])        # TODO: 确保 输入grid + temp_i, 前向传播\n",
        "        loss    = criterion(output, items[:, 1:]) # TODO: 确保 输入 temp_i 以后的\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Append predictions and actual values to the lists\n",
        "        predictions_scaled.extend(output.cpu())         # Move predictions to CPU\n",
        "        actual_values_scaled.extend(items[:, 1:].cpu()) # Move actual values to CPU\n",
        "\n",
        "print(f\"Test Loss: {total_loss / len(test_loader):.4f}\")"
      ],
      "metadata": {
        "id": "5zn0vY-6nIZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 打印平均损失\n",
        "average_loss = total_loss / len(test_loader)\n",
        "print(f'Average loss on the test data: {average_loss:.5f}')"
      ],
      "metadata": {
        "id": "1i-7pkgonrqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 转换为 numpy 数组，方便绘图\n",
        "predictions_scaled   = np.array(predictions_scaled).copy()\n",
        "actual_values_scaled = np.array(actual_values_scaled).copy()\n",
        "\n",
        "# 反归一化\n",
        "reverse_nromalization = False\n",
        "if reverse_nromalization:\n",
        "  scaler          = joblib.load(\"scaler.pkl\")\n",
        "  scaler.min_     = scaler.min_[1:] # 只选择 scaler 的前 2 维\n",
        "  scaler.scale_   = scaler.scale_[1:]\n",
        "  predictions     = scaler.inverse_transform(predictions_scaled)\n",
        "  actual_values   = scaler.inverse_transform(actual_values_scaled)\n",
        "else:\n",
        "  predictions     = predictions_scaled\n",
        "  actual_values   = actual_values_scaled"
      ],
      "metadata": {
        "id": "Uqi8OUosdIqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_prediction_results(actual_values, predictions, target_idx, target_name):\n",
        "    \"\"\"\n",
        "    绘制预测结果分析图（预测 vs 真实值、误差分布、误差 vs 真实值）\n",
        "\n",
        "    参数：\n",
        "    - actual_values: 真实值的 NumPy 数组 (N, 2)\n",
        "    - predictions: 预测值的 NumPy 数组 (N, 2)\n",
        "    - target_idx: 目标变量索引（0 或 1）\n",
        "    - target_name: 目标变量的名称 (str)\n",
        "    \"\"\"\n",
        "    errors = predictions[:, target_idx] - actual_values[:, target_idx]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # 1️⃣ 预测值 vs 真实值\n",
        "    axes[0].scatter(actual_values[:, target_idx], predictions[:, target_idx], c='blue', label='Predictions')\n",
        "    axes[0].plot([min(actual_values[:, target_idx]), max(actual_values[:, target_idx])],\n",
        "                 [min(actual_values[:, target_idx]), max(actual_values[:, target_idx])], 'r--', label='Ideal fit')\n",
        "    axes[0].set_xlabel(f'Actual Values ({target_name})')\n",
        "    axes[0].set_ylabel(f'Predicted Values ({target_name})')\n",
        "    axes[0].set_title(f'Predicted vs Actual Values ({target_name})')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # 2️⃣ 误差分布直方图\n",
        "    axes[1].hist(errors, bins=25, color='purple', edgecolor='black')\n",
        "    axes[1].set_xlabel(f'Prediction Error ({target_name})')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    axes[1].set_title(f'Distribution of Prediction Errors ({target_name})')\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # 3️⃣ 误差 vs 真实值\n",
        "    axes[2].scatter(actual_values[:, target_idx], errors, c='green')\n",
        "    axes[2].axhline(y=0, color='r', linestyle='--')\n",
        "    axes[2].set_xlabel(f'Actual Values ({target_name})')\n",
        "    axes[2].set_ylabel(f'Prediction Error ({target_name})')\n",
        "    axes[2].set_title(f'Prediction Error vs Actual Values ({target_name})')\n",
        "    axes[2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'Prediction_Results_{target_name}.png')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Tnu_agM1nu8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 调用函数绘制目标值 1 (Target 1)\n",
        "plot_prediction_results(actual_values, predictions, target_idx=0, target_name=\"Target 1\")"
      ],
      "metadata": {
        "id": "zyXRYNe6eQCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 调用函数绘制目标值 2 (Target 2)\n",
        "plot_prediction_results(actual_values, predictions, target_idx=1, target_name=\"Target 2\")"
      ],
      "metadata": {
        "id": "05pSaJ_deSz1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}